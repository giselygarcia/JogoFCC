{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExecutandoCUDA.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBIJ0YM5Bgbn"
      },
      "source": [
        "!apt update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWig3zjYCYP_"
      },
      "source": [
        "!apt search cuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LcoqfDOCl8I",
        "outputId": "1d25bd4c-906b-4053-a82a-36f4fb16b160",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!apt install cuda-10-2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  cuda-command-line-tools-10-2 cuda-compiler-10-2 cuda-cudart-10-2\n",
            "  cuda-cudart-dev-10-2 cuda-cufft-10-2 cuda-cufft-dev-10-2 cuda-cuobjdump-10-2\n",
            "  cuda-cupti-10-2 cuda-cupti-dev-10-2 cuda-curand-10-2 cuda-curand-dev-10-2\n",
            "  cuda-cusolver-10-2 cuda-cusolver-dev-10-2 cuda-cusparse-10-2\n",
            "  cuda-cusparse-dev-10-2 cuda-demo-suite-10-2 cuda-documentation-10-2\n",
            "  cuda-driver-dev-10-2 cuda-gdb-10-2 cuda-libraries-10-2\n",
            "  cuda-libraries-dev-10-2 cuda-license-10-2 cuda-memcheck-10-2\n",
            "  cuda-misc-headers-10-2 cuda-npp-10-2 cuda-npp-dev-10-2 cuda-nsight-10-2\n",
            "  cuda-nsight-compute-10-2 cuda-nsight-systems-10-2 cuda-nvcc-10-2\n",
            "  cuda-nvdisasm-10-2 cuda-nvgraph-10-2 cuda-nvgraph-dev-10-2 cuda-nvjpeg-10-2\n",
            "  cuda-nvjpeg-dev-10-2 cuda-nvml-dev-10-2 cuda-nvprof-10-2 cuda-nvprune-10-2\n",
            "  cuda-nvrtc-10-2 cuda-nvrtc-dev-10-2 cuda-nvtx-10-2 cuda-nvvp-10-2\n",
            "  cuda-runtime-10-2 cuda-samples-10-2 cuda-sanitizer-api-10-2\n",
            "  cuda-toolkit-10-2 cuda-tools-10-2 cuda-visual-tools-10-2 libcublas-dev\n",
            "  libcublas10\n",
            "The following NEW packages will be installed:\n",
            "  cuda-10-2 cuda-command-line-tools-10-2 cuda-compiler-10-2 cuda-cudart-10-2\n",
            "  cuda-cudart-dev-10-2 cuda-cufft-10-2 cuda-cufft-dev-10-2 cuda-cuobjdump-10-2\n",
            "  cuda-cupti-10-2 cuda-cupti-dev-10-2 cuda-curand-10-2 cuda-curand-dev-10-2\n",
            "  cuda-cusolver-10-2 cuda-cusolver-dev-10-2 cuda-cusparse-10-2\n",
            "  cuda-cusparse-dev-10-2 cuda-demo-suite-10-2 cuda-documentation-10-2\n",
            "  cuda-driver-dev-10-2 cuda-gdb-10-2 cuda-libraries-10-2\n",
            "  cuda-libraries-dev-10-2 cuda-license-10-2 cuda-memcheck-10-2\n",
            "  cuda-misc-headers-10-2 cuda-npp-10-2 cuda-npp-dev-10-2 cuda-nsight-10-2\n",
            "  cuda-nsight-compute-10-2 cuda-nsight-systems-10-2 cuda-nvcc-10-2\n",
            "  cuda-nvdisasm-10-2 cuda-nvgraph-10-2 cuda-nvgraph-dev-10-2 cuda-nvjpeg-10-2\n",
            "  cuda-nvjpeg-dev-10-2 cuda-nvml-dev-10-2 cuda-nvprof-10-2 cuda-nvprune-10-2\n",
            "  cuda-nvrtc-10-2 cuda-nvrtc-dev-10-2 cuda-nvtx-10-2 cuda-nvvp-10-2\n",
            "  cuda-runtime-10-2 cuda-samples-10-2 cuda-sanitizer-api-10-2\n",
            "  cuda-toolkit-10-2 cuda-tools-10-2 cuda-visual-tools-10-2\n",
            "The following packages will be upgraded:\n",
            "  libcublas-dev libcublas10\n",
            "2 upgraded, 49 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 1,429 MB of archives.\n",
            "After this operation, 3,272 MB of additional disk space will be used.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-license-10-2 10.2.89-1 [16.4 kB]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-misc-headers-10-2 10.2.89-1 [1,111 kB]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvcc-10-2 10.2.89-1 [37.4 MB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cuobjdump-10-2 10.2.89-1 [88.5 kB]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvprune-10-2 10.2.89-1 [39.5 kB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-compiler-10-2 10.2.89-1 [2,530 B]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvdisasm-10-2 10.2.89-1 [22.2 MB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-gdb-10-2 10.2.89-1 [2,769 kB]\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvprof-10-2 10.2.89-1 [1,651 kB]\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-sanitizer-api-10-2 10.2.89-1 [2,161 kB]\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-memcheck-10-2 10.2.89-1 [139 kB]\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cudart-10-2 10.2.89-1 [111 kB]\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-driver-dev-10-2 10.2.89-1 [11.8 kB]\n",
            "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cudart-dev-10-2 10.2.89-1 [491 kB]\n",
            "Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cupti-10-2 10.2.89-1 [8,169 kB]\n",
            "Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cupti-dev-10-2 10.2.89-1 [2,197 kB]\n",
            "Get:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvtx-10-2 10.2.89-1 [38.9 kB]\n",
            "Get:18 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-command-line-tools-10-2 10.2.89-1 [27.0 kB]\n",
            "Get:19 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nsight-10-2 10.2.89-1 [2,582 B]\n",
            "Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvvp-10-2 10.2.89-1 [2,532 B]\n",
            "Get:21 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvrtc-10-2 10.2.89-1 [6,413 kB]\n",
            "Get:22 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvrtc-dev-10-2 10.2.89-1 [8,822 B]\n",
            "Get:23 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cusolver-10-2 10.2.89-1 [85.6 MB]\n",
            "Get:24 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cusolver-dev-10-2 10.2.89-1 [15.2 MB]\n",
            "Get:25 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcublas10 10.2.3.254-1 [43.1 MB]\n",
            "Get:26 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcublas-dev 10.2.3.254-1 [42.4 MB]\n",
            "Get:27 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cufft-10-2 10.2.89-1 [87.8 MB]\n",
            "Get:28 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cufft-dev-10-2 10.2.89-1 [164 MB]\n",
            "Get:29 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-curand-10-2 10.2.89-1 [38.9 MB]\n",
            "Get:30 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-curand-dev-10-2 10.2.89-1 [39.1 MB]\n",
            "Get:31 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cusparse-10-2 10.2.89-1 [59.2 MB]\n",
            "Get:32 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cusparse-dev-10-2 10.2.89-1 [59.7 MB]\n",
            "Get:33 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-npp-10-2 10.2.89-1 [56.7 MB]\n",
            "Get:34 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-npp-dev-10-2 10.2.89-1 [57.6 MB]\n",
            "Get:35 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvml-dev-10-2 10.2.89-1 [53.8 kB]\n",
            "Get:36 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvjpeg-10-2 10.2.89-1 [1,274 kB]\n",
            "Get:37 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvjpeg-dev-10-2 10.2.89-1 [1,213 kB]\n",
            "Get:38 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nsight-compute-10-2 10.2.89-1 [3,712 B]\n",
            "Get:39 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nsight-systems-10-2 10.2.89-1 [3,130 B]\n",
            "Get:40 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvgraph-10-2 10.2.89-1 [44.5 MB]\n",
            "Get:41 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvgraph-dev-10-2 10.2.89-1 [35.2 MB]\n",
            "Get:42 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-visual-tools-10-2 10.2.89-1 [389 MB]\n",
            "Get:43 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-tools-10-2 10.2.89-1 [2,496 B]\n",
            "Get:44 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-samples-10-2 10.2.89-1 [65.6 MB]\n",
            "Get:45 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-documentation-10-2 10.2.89-1 [54.1 MB]\n",
            "Get:46 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-libraries-dev-10-2 10.2.89-1 [2,614 B]\n",
            "Get:47 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-libraries-10-2 10.2.89-1 [2,584 B]\n",
            "Get:48 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-toolkit-10-2 10.2.89-1 [2,830 B]\n",
            "Get:49 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-runtime-10-2 10.2.89-1 [2,532 B]\n",
            "Get:50 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-demo-suite-10-2 10.2.89-1 [3,880 kB]\n",
            "Get:51 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-10-2 10.2.89-1 [2,558 B]\n",
            "Fetched 1,429 MB in 30s (48.4 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package cuda-license-10-2.\n",
            "(Reading database ... 155047 files and directories currently installed.)\n",
            "Preparing to unpack .../00-cuda-license-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-license-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-misc-headers-10-2.\n",
            "Preparing to unpack .../01-cuda-misc-headers-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-misc-headers-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nvcc-10-2.\n",
            "Preparing to unpack .../02-cuda-nvcc-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvcc-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-cuobjdump-10-2.\n",
            "Preparing to unpack .../03-cuda-cuobjdump-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-cuobjdump-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nvprune-10-2.\n",
            "Preparing to unpack .../04-cuda-nvprune-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvprune-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-compiler-10-2.\n",
            "Preparing to unpack .../05-cuda-compiler-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-compiler-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nvdisasm-10-2.\n",
            "Preparing to unpack .../06-cuda-nvdisasm-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvdisasm-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-gdb-10-2.\n",
            "Preparing to unpack .../07-cuda-gdb-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-gdb-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nvprof-10-2.\n",
            "Preparing to unpack .../08-cuda-nvprof-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvprof-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-sanitizer-api-10-2.\n",
            "Preparing to unpack .../09-cuda-sanitizer-api-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-sanitizer-api-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-memcheck-10-2.\n",
            "Preparing to unpack .../10-cuda-memcheck-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-memcheck-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-cudart-10-2.\n",
            "Preparing to unpack .../11-cuda-cudart-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-cudart-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-driver-dev-10-2.\n",
            "Preparing to unpack .../12-cuda-driver-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-driver-dev-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-cudart-dev-10-2.\n",
            "Preparing to unpack .../13-cuda-cudart-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-cudart-dev-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-cupti-10-2.\n",
            "Preparing to unpack .../14-cuda-cupti-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-cupti-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-cupti-dev-10-2.\n",
            "Preparing to unpack .../15-cuda-cupti-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-cupti-dev-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nvtx-10-2.\n",
            "Preparing to unpack .../16-cuda-nvtx-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvtx-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-command-line-tools-10-2.\n",
            "Preparing to unpack .../17-cuda-command-line-tools-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-command-line-tools-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nsight-10-2.\n",
            "Preparing to unpack .../18-cuda-nsight-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nsight-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nvvp-10-2.\n",
            "Preparing to unpack .../19-cuda-nvvp-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvvp-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nvrtc-10-2.\n",
            "Preparing to unpack .../20-cuda-nvrtc-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvrtc-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nvrtc-dev-10-2.\n",
            "Preparing to unpack .../21-cuda-nvrtc-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvrtc-dev-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-cusolver-10-2.\n",
            "Preparing to unpack .../22-cuda-cusolver-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-cusolver-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-cusolver-dev-10-2.\n",
            "Preparing to unpack .../23-cuda-cusolver-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-cusolver-dev-10-2 (10.2.89-1) ...\n",
            "Preparing to unpack .../24-libcublas10_10.2.3.254-1_amd64.deb ...\n",
            "Unpacking libcublas10 (10.2.3.254-1) over (10.2.1.243-1) ...\n",
            "Preparing to unpack .../25-libcublas-dev_10.2.3.254-1_amd64.deb ...\n",
            "Unpacking libcublas-dev (10.2.3.254-1) over (10.2.1.243-1) ...\n",
            "Selecting previously unselected package cuda-cufft-10-2.\n",
            "Preparing to unpack .../26-cuda-cufft-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-cufft-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-cufft-dev-10-2.\n",
            "Preparing to unpack .../27-cuda-cufft-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-cufft-dev-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-curand-10-2.\n",
            "Preparing to unpack .../28-cuda-curand-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-curand-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-curand-dev-10-2.\n",
            "Preparing to unpack .../29-cuda-curand-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-curand-dev-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-cusparse-10-2.\n",
            "Preparing to unpack .../30-cuda-cusparse-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-cusparse-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-cusparse-dev-10-2.\n",
            "Preparing to unpack .../31-cuda-cusparse-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-cusparse-dev-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-npp-10-2.\n",
            "Preparing to unpack .../32-cuda-npp-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-npp-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-npp-dev-10-2.\n",
            "Preparing to unpack .../33-cuda-npp-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-npp-dev-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nvml-dev-10-2.\n",
            "Preparing to unpack .../34-cuda-nvml-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvml-dev-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nvjpeg-10-2.\n",
            "Preparing to unpack .../35-cuda-nvjpeg-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvjpeg-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nvjpeg-dev-10-2.\n",
            "Preparing to unpack .../36-cuda-nvjpeg-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvjpeg-dev-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nsight-compute-10-2.\n",
            "Preparing to unpack .../37-cuda-nsight-compute-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nsight-compute-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nsight-systems-10-2.\n",
            "Preparing to unpack .../38-cuda-nsight-systems-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nsight-systems-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nvgraph-10-2.\n",
            "Preparing to unpack .../39-cuda-nvgraph-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvgraph-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nvgraph-dev-10-2.\n",
            "Preparing to unpack .../40-cuda-nvgraph-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvgraph-dev-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-visual-tools-10-2.\n",
            "Preparing to unpack .../41-cuda-visual-tools-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-visual-tools-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-tools-10-2.\n",
            "Preparing to unpack .../42-cuda-tools-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-tools-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-samples-10-2.\n",
            "Preparing to unpack .../43-cuda-samples-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-samples-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-documentation-10-2.\n",
            "Preparing to unpack .../44-cuda-documentation-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-documentation-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-libraries-dev-10-2.\n",
            "Preparing to unpack .../45-cuda-libraries-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-libraries-dev-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-libraries-10-2.\n",
            "Preparing to unpack .../46-cuda-libraries-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-libraries-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-toolkit-10-2.\n",
            "Preparing to unpack .../47-cuda-toolkit-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-toolkit-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-runtime-10-2.\n",
            "Preparing to unpack .../48-cuda-runtime-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-runtime-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-demo-suite-10-2.\n",
            "Preparing to unpack .../49-cuda-demo-suite-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-demo-suite-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-10-2.\n",
            "Preparing to unpack .../50-cuda-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-license-10-2 (10.2.89-1) ...\n",
            "*** LICENSE AGREEMENT ***\n",
            "By using this software you agree to fully comply with the terms and \n",
            "conditions of the EULA (End User License Agreement). The EULA is located\n",
            "at /usr/local/cuda-10.2/doc/EULA.txt. The EULA can also be found at\n",
            "http://docs.nvidia.com/cuda/eula/index.html. If you do not agree to the\n",
            "terms and conditions of the EULA, do not use the software.\n",
            "\n",
            "Setting up cuda-nvgraph-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nvprune-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nvrtc-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nvtx-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nvjpeg-10-2 (10.2.89-1) ...\n",
            "Setting up libcublas10 (10.2.3.254-1) ...\n",
            "Setting up libcublas-dev (10.2.3.254-1) ...\n",
            "Setting up cuda-cufft-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nsight-compute-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-cusparse-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-cuobjdump-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-sanitizer-api-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nvjpeg-dev-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-cusolver-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-misc-headers-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nvvp-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-curand-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-cudart-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-npp-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-cufft-dev-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-libraries-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-memcheck-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nvrtc-dev-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-driver-dev-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-npp-dev-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nsight-systems-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nsight-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nvdisasm-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nvml-dev-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nvgraph-dev-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nvcc-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nvprof-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-cusparse-dev-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-compiler-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-runtime-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-curand-dev-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-cusolver-dev-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-demo-suite-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-gdb-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-cudart-dev-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-libraries-dev-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-visual-tools-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-samples-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-cupti-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-documentation-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-cupti-dev-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-command-line-tools-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-tools-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-toolkit-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-10-2 (10.2.89-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHkQcimiPSVt",
        "outputId": "0e44ee29-22f4-47f1-db21-0aa2ba648ed1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Oct 22 23:14:17 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYaNIMpJDQSI",
        "outputId": "89b9734c-86b1-4b07-b2e5-3d92b3cb1950",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!man nvidia-smi"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvidia-smi(1)                       NVIDIA                       nvidia-smi(1)\n",
            "\n",
            "N\bNA\bAM\bME\bE\n",
            "       nvidia-smi - NVIDIA System Management Interface program\n",
            "\n",
            "S\bSY\bYN\bNO\bOP\bPS\bSI\bIS\bS\n",
            "       nvidia-smi [OPTION1 [ARG1]] [OPTION2 [ARG2]] ...\n",
            "\n",
            "D\bDE\bES\bSC\bCR\bRI\bIP\bPT\bTI\bIO\bON\bN\n",
            "       nvidia-smi (also NVSMI) provides monitoring and management capabilities\n",
            "       for each of NVIDIA's Tesla, Quadro, GRID and GeForce devices from Fermi\n",
            "       and higher architecture families. GeForce Titan series devices are sup‐\n",
            "       ported for most functions with very limited  information  provided  for\n",
            "       the  remainder  of  the  Geforce brand.  NVSMI is a cross platform tool\n",
            "       that supports all standard NVIDIA driver-supported  Linux  distros,  as\n",
            "       well as 64bit versions of Windows starting with Windows Server 2008 R2.\n",
            "       Metrics can be consumed directly by users via stdout,  or  provided  by\n",
            "       file via CSV and XML formats for scripting purposes.\n",
            "\n",
            "       Note  that much of the functionality of NVSMI is provided by the under‐\n",
            "       lying NVML C-based library.  See  the  NVIDIA  developer  website  link\n",
            "       below  for more information about NVML.  NVML-based python bindings are\n",
            "       also available.\n",
            "\n",
            "       The output of NVSMI is not guaranteed to be backwards compatible.  How‐\n",
            "       ever,  both  NVML and the Python bindings are backwards compatible, and\n",
            "       should be the first choice when writing any tools that  must  be  main‐\n",
            "       tained across NVIDIA driver releases.\n",
            "\n",
            "       N\bNV\bVM\bML\bL S\bSD\bDK\bK:\b: _\bh_\bt_\bt_\bp_\b:_\b/_\b/_\bd_\be_\bv_\be_\bl_\bo_\bp_\be_\br_\b._\bn_\bv_\bi_\bd_\bi_\ba_\b._\bc_\bo_\bm_\b/_\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bm_\ba_\bn_\ba_\bg_\be_\bm_\be_\bn_\bt_\b-_\bl_\bi_\bb_\br_\ba_\br_\by_\b-_\bn_\bv_\bm_\bl_\b/\n",
            "\n",
            "       P\bPy\byt\bth\bho\bon\bn b\bbi\bin\bnd\bdi\bin\bng\bgs\bs:\b: _\bh_\bt_\bt_\bp_\b:_\b/_\b/_\bp_\by_\bp_\bi_\b._\bp_\by_\bt_\bh_\bo_\bn_\b._\bo_\br_\bg_\b/_\bp_\by_\bp_\bi_\b/_\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bm_\bl_\b-_\bp_\by_\b/\n",
            "\n",
            "O\bOP\bPT\bTI\bIO\bON\bNS\bS\n",
            "   G\bGE\bEN\bNE\bER\bRA\bAL\bL O\bOP\bPT\bTI\bIO\bON\bNS\bS\n",
            "   -\b-h\bh,\b, -\b--\b-h\bhe\bel\blp\bp\n",
            "       Print usage information and exit.\n",
            "\n",
            "   S\bSU\bUM\bMM\bMA\bAR\bRY\bY O\bOP\bPT\bTI\bIO\bON\bNS\bS\n",
            "   -\b-L\bL,\b, -\b--\b-l\bli\bis\bst\bt-\b-g\bgp\bpu\bus\bs\n",
            "       List each of the NVIDIA GPUs in the system, along with their UUIDs.\n",
            "\n",
            "   -\b-B\bB,\b, -\b--\b-l\bli\bis\bst\bt-\b-e\bex\bxc\bcl\blu\bud\bde\bed\bd-\b-g\bgp\bpu\bus\bs\n",
            "       List  each  of the excluded NVIDIA GPUs in the system, along with their\n",
            "       UUIDs.\n",
            "\n",
            "   Q\bQU\bUE\bER\bRY\bY O\bOP\bPT\bTI\bIO\bON\bNS\bS\n",
            "   -\b-q\bq,\b, -\b--\b-q\bqu\bue\ber\bry\by\n",
            "       Display GPU or Unit info.  Displayed info includes all data  listed  in\n",
            "       the  (_\bG_\bP_\bU  _\bA_\bT_\bT_\bR_\bI_\bB_\bU_\bT_\bE_\bS)  or (_\bU_\bN_\bI_\bT _\bA_\bT_\bT_\bR_\bI_\bB_\bU_\bT_\bE_\bS) sections of this document.\n",
            "       Some devices and/or environments don't support  all  possible  informa‐\n",
            "       tion.   Any unsupported data is indicated by a \"N/A\" in the output.  By\n",
            "       default information for all available GPUs or Units is displayed.   Use\n",
            "       the -\b-i\bi option to restrict the output to a single GPU or Unit.\n",
            "\n",
            "   [\b[p\bpl\blu\bus\bs o\bop\bpt\bti\bio\bon\bna\bal\bl]\b]\n",
            "   -\b-u\bu,\b, -\b--\b-u\bun\bni\bit\bt\n",
            "       Display Unit data instead of GPU data.  Unit data is only available for\n",
            "       NVIDIA S-class Tesla enclosures.\n",
            "\n",
            "   -\b-i\bi,\b, -\b--\b-i\bid\bd=\b=I\bID\bD\n",
            "       Display data for a single specified GPU or Unit.  The specified id  may\n",
            "       be  the GPU/Unit's 0-based index in the natural enumeration returned by\n",
            "       the driver, the GPU's board serial number, the GPU's UUID, or the GPU's\n",
            "       PCI  bus  ID (as domain:bus:device.function in hex).  It is recommended\n",
            "       that users desiring consistency use either UUID or PCI  bus  ID,  since\n",
            "       device  enumeration ordering is not guaranteed to be consistent between\n",
            "       reboots and board serial number might be shared between  multiple  GPUs\n",
            "       on the same board.\n",
            "\n",
            "   -\b-f\bf F\bFI\bIL\bLE\bE,\b, -\b--\b-f\bfi\bil\ble\ben\bna\bam\bme\be=\b=F\bFI\bIL\bLE\bE\n",
            "       Redirect  query  output  to  the specified file in place of the default\n",
            "       stdout.  The specified file will be overwritten.\n",
            "\n",
            "   -\b-x\bx,\b, -\b--\b-x\bxm\bml\bl-\b-f\bfo\bor\brm\bma\bat\bt\n",
            "       Produce XML output in place of the default human-readable format.  Both\n",
            "       GPU  and  Unit  query outputs conform to corresponding DTDs.  These are\n",
            "       available via the -\b--\b-d\bdt\btd\bd flag.\n",
            "\n",
            "   -\b--\b-d\bdt\btd\bd\n",
            "       Use with -\b-x\bx.  Embed the DTD in the XML output.\n",
            "\n",
            "   -\b--\b-d\bde\beb\bbu\bug\bg=\b=F\bFI\bIL\bLE\bE\n",
            "       Produces an encrypted debug log for use in submission of bugs  back  to\n",
            "       NVIDIA.\n",
            "\n",
            "   -\b-d\bd T\bTY\bYP\bPE\bE,\b, -\b--\b-d\bdi\bis\bsp\bpl\bla\bay\by=\b=T\bTY\bYP\bPE\bE\n",
            "       Display  only  selected information: MEMORY, UTILIZATION, ECC, TEMPERA‐\n",
            "       TURE,  POWER,  CLOCK,  COMPUTE,  PIDS,  PERFORMANCE,  SUPPORTED_CLOCKS,\n",
            "       PAGE_RETIREMENT,   ACCOUNTING,  ENCODER_STATS,  ROW_REMAPPER,  VOLTAGE.\n",
            "       Flags can be combined with comma  e.g.   \"MEMORY,ECC\".   Sampling  data\n",
            "       with max, min and avg is also returned for POWER, UTILIZATION and CLOCK\n",
            "       display types.  Doesn't work with -u/--unit or -x/--xml-format flags.\n",
            "\n",
            "   -\b-l\bl S\bSE\bEC\bC,\b, -\b--\b-l\blo\boo\bop\bp=\b=S\bSE\bEC\bC\n",
            "       Continuously report query data at the specified interval,  rather  than\n",
            "       the  default  of  just  once.   The  application  will sleep in-between\n",
            "       queries.  Note that on Linux ECC error or XID error events  will  print\n",
            "       out during the sleep period if the _\b-_\bx flag was not specified.  Pressing\n",
            "       Ctrl+C at any time will abort the loop, which will otherwise run indef‐\n",
            "       initely.   If no argument is specified for the -\b-l\bl form a default inter‐\n",
            "       val of 5 seconds is used.\n",
            "\n",
            "   S\bSE\bEL\bLE\bEC\bCT\bTI\bIV\bVE\bE Q\bQU\bUE\bER\bRY\bY O\bOP\bPT\bTI\bIO\bON\bNS\bS\n",
            "       Allows the caller to pass an explicit list of properties to query.\n",
            "\n",
            "   [\b[o\bon\bne\be o\bof\bf]\b]\n",
            "   -\b--\b-q\bqu\bue\ber\bry\by-\b-g\bgp\bpu\bu=\b=\n",
            "       Information about GPU.  Pass comma separated  list  of  properties  you\n",
            "       want  to  query.   e.g.  --query-gpu=pci.bus_id,persistence_mode.  Call\n",
            "       --help-query-gpu for more info.\n",
            "\n",
            "   -\b--\b-q\bqu\bue\ber\bry\by-\b-s\bsu\bup\bpp\bpo\bor\brt\bte\bed\bd-\b-c\bcl\blo\boc\bck\bks\bs=\b=\n",
            "       List of supported clocks.  Call --help-query-supported-clocks for  more\n",
            "       info.\n",
            "\n",
            "   -\b--\b-q\bqu\bue\ber\bry\by-\b-c\bco\bom\bmp\bpu\but\bte\be-\b-a\bap\bpp\bps\bs=\b=\n",
            "       List  of  currently  active  compute processes.  Call --help-query-com‐\n",
            "       pute-apps for more info.\n",
            "\n",
            "   -\b--\b-q\bqu\bue\ber\bry\by-\b-a\bac\bcc\bco\bou\bun\bnt\bte\bed\bd-\b-a\bap\bpp\bps\bs=\b=\n",
            "       List of accounted compute processes.  Call  --help-query-accounted-apps\n",
            "       for more info.  This query is not supported on vGPU host.\n",
            "\n",
            "   -\b--\b-q\bqu\bue\ber\bry\by-\b-r\bre\bet\bti\bir\bre\bed\bd-\b-p\bpa\bag\bge\bes\bs=\b=\n",
            "       List  of  GPU  device  memory  pages  that  have  been  retired.   Call\n",
            "       --help-query-retired-pages for more info.\n",
            "\n",
            "   -\b--\b-q\bqu\bue\ber\bry\by-\b-r\bre\bem\bma\bap\bpp\bpe\bed\bd-\b-r\bro\bow\bws\bs=\b=\n",
            "       Information about remapped rows.  Call  --help-query-remapped-rows  for\n",
            "       more info.\n",
            "\n",
            "   [\b[m\bma\ban\bnd\bda\bat\bto\bor\bry\by]\b]\n",
            "   -\b--\b-f\bfo\bor\brm\bma\bat\bt=\b=\n",
            "       Comma separated list of format options:\n",
            "\n",
            "       ·      csv - comma separated values (MANDATORY)\n",
            "\n",
            "       ·      noheader - skip first line with column headers\n",
            "\n",
            "       ·      nounits - don't print units for numerical values\n",
            "\n",
            "   [\b[p\bpl\blu\bus\bs a\ban\bny\by o\bof\bf]\b]\n",
            "   -\b-i\bi,\b, -\b--\b-i\bid\bd=\b=I\bID\bD\n",
            "       Display  data  for a single specified GPU.  The specified id may be the\n",
            "       GPU's 0-based index in the natural enumeration returned by the  driver,\n",
            "       the  GPU's board serial number, the GPU's UUID, or the GPU's PCI bus ID\n",
            "       (as domain:bus:device.function in hex).  It is recommended  that  users\n",
            "       desiring  consistency  use either UUID or PCI bus ID, since device enu‐\n",
            "       meration ordering is not guaranteed to be  consistent  between  reboots\n",
            "       and  board  serial  number might be shared between multiple GPUs on the\n",
            "       same board.\n",
            "\n",
            "   -\b-f\bf F\bFI\bIL\bLE\bE,\b, -\b--\b-f\bfi\bil\ble\ben\bna\bam\bme\be=\b=F\bFI\bIL\bLE\bE\n",
            "       Redirect query output to the specified file in  place  of  the  default\n",
            "       stdout.  The specified file will be overwritten.\n",
            "\n",
            "   -\b-l\bl S\bSE\bEC\bC,\b, -\b--\b-l\blo\boo\bop\bp=\b=S\bSE\bEC\bC\n",
            "       Continuously  report  query data at the specified interval, rather than\n",
            "       the default of  just  once.   The  application  will  sleep  in-between\n",
            "       queries.   Note  that on Linux ECC error or XID error events will print\n",
            "       out during the sleep period if the _\b-_\bx flag was not specified.  Pressing\n",
            "       Ctrl+C at any time will abort the loop, which will otherwise run indef‐\n",
            "       initely.  If no argument is specified for the -\b-l\bl form a default  inter‐\n",
            "       val of 5 seconds is used.\n",
            "\n",
            "   -\b-l\blm\bms\bs m\bms\bs,\b, -\b--\b-l\blo\boo\bop\bp-\b-m\bms\bs=\b=m\bms\bs\n",
            "       Same as -l,--loop but in milliseconds.\n",
            "\n",
            "   D\bDE\bEV\bVI\bIC\bCE\bE M\bMO\bOD\bDI\bIF\bFI\bIC\bCA\bAT\bTI\bIO\bON\bN O\bOP\bPT\bTI\bIO\bON\bNS\bS\n",
            "   [\b[a\ban\bny\by o\bon\bne\be o\bof\bf]\b]\n",
            "   -\b-p\bpm\bm,\b, -\b--\b-p\bpe\ber\brs\bsi\bis\bst\bte\ben\bnc\bce\be-\b-m\bmo\bod\bde\be=\b=M\bMO\bOD\bDE\bE\n",
            "       Set the persistence mode for the target GPUs.  See the (_\bG_\bP_\bU _\bA_\bT_\bT_\bR_\bI_\bB_\bU_\bT_\bE_\bS)\n",
            "       section for a description of persistence mode.   Requires  root.   Will\n",
            "       impact all GPUs unless a single GPU is specified using the _\b-_\bi argument.\n",
            "       The effect of this operation is immediate.  However, it does  not  per‐\n",
            "       sist  across  reboots.  After each reboot persistence mode will default\n",
            "       to \"Disabled\".  Available on Linux only.\n",
            "\n",
            "   -\b-e\be,\b, -\b--\b-e\bec\bcc\bc-\b-c\bco\bon\bnf\bfi\big\bg=\b=C\bCO\bON\bNF\bFI\bIG\bG\n",
            "       Set the ECC mode for the target GPUs.  See the (_\bG_\bP_\bU _\bA_\bT_\bT_\bR_\bI_\bB_\bU_\bT_\bE_\bS) section\n",
            "       for  a  description  of ECC mode.  Requires root.  Will impact all GPUs\n",
            "       unless a single GPU is specified using the _\b-_\bi argument.   This  setting\n",
            "       takes effect after the next reboot and is persistent.\n",
            "\n",
            "   -\b-p\bp,\b, -\b--\b-r\bre\bes\bse\bet\bt-\b-e\bec\bcc\bc-\b-e\ber\brr\bro\bor\brs\bs=\b=T\bTY\bYP\bPE\bE\n",
            "       Reset  the  ECC  error  counters  for  the  target  GPUs.  See the (_\bG_\bP_\bU\n",
            "       _\bA_\bT_\bT_\bR_\bI_\bB_\bU_\bT_\bE_\bS) section for a  description  of  ECC  error  counter  types.\n",
            "       Available  arguments  are  0|VOLATILE  or  1|AGGREGATE.  Requires root.\n",
            "       Will impact all GPUs unless a single GPU  is  specified  using  the  _\b-_\bi\n",
            "       argument.  The effect of this operation is immediate.\n",
            "\n",
            "   -\b-c\bc,\b, -\b--\b-c\bco\bom\bmp\bpu\but\bte\be-\b-m\bmo\bod\bde\be=\b=M\bMO\bOD\bDE\bE\n",
            "       Set  the  compute  mode  for the target GPUs.  See the (_\bG_\bP_\bU _\bA_\bT_\bT_\bR_\bI_\bB_\bU_\bT_\bE_\bS)\n",
            "       section for a description of compute mode.  Requires root.  Will impact\n",
            "       all  GPUs  unless a single GPU is specified using the _\b-_\bi argument.  The\n",
            "       effect of this operation is immediate.  However, it  does  not  persist\n",
            "       across   reboots.   After  each  reboot  compute  mode  will  reset  to\n",
            "       \"DEFAULT\".\n",
            "\n",
            "   -\b-d\bdm\bm T\bTY\bYP\bPE\bE,\b, -\b--\b-d\bdr\bri\biv\bve\ber\br-\b-m\bmo\bod\bde\bel\bl=\b=T\bTY\bYP\bPE\bE\n",
            "   -\b-f\bfd\bdm\bm T\bTY\bYP\bPE\bE,\b, -\b--\b-f\bfo\bor\brc\bce\be-\b-d\bdr\bri\biv\bve\ber\br-\b-m\bmo\bod\bde\bel\bl=\b=T\bTY\bYP\bPE\bE\n",
            "       Enable or disable TCC driver model.  For Windows only.  Requires admin‐\n",
            "       istrator  privileges.  _\b-_\bd_\bm will fail if a display is attached, but _\b-_\bf_\bd_\bm\n",
            "       will force the driver model to change.  Will impact all GPUs  unless  a\n",
            "       single  GPU  is  specified using the _\b-_\bi argument.  A reboot is required\n",
            "       for the change to take place.  See D\bDr\bri\biv\bve\ber\br M\bMo\bod\bde\bel\bl for more information on\n",
            "       Windows driver models.\n",
            "\n",
            "        -\b--\b-g\bgo\bom\bm=\b=M\bMO\bOD\bDE\bE\n",
            "       Set  GPU  Operation  Mode:  0/ALL_ON,  1/COMPUTE, 2/LOW_DP Supported on\n",
            "       GK110 M-class and X-class Tesla products from the Kepler  family.   Not\n",
            "       supported  on Quadro and Tesla C-class products.  LOW_DP and ALL_ON are\n",
            "       the only modes supported on GeForce Titan devices.   Requires  adminis‐\n",
            "       trator  privileges.   See _\bG_\bP_\bU _\bO_\bp_\be_\br_\ba_\bt_\bi_\bo_\bn _\bM_\bo_\bd_\be for more information about\n",
            "       GOM.  GOM changes take effect after  reboot.   The  reboot  requirement\n",
            "       might  be  removed in the future.  Compute only GOMs don't support WDDM\n",
            "       (Windows Display Driver Model)\n",
            "\n",
            "   -\b-r\br,\b, -\b--\b-g\bgp\bpu\bu-\b-r\bre\bes\bse\bet\bt\n",
            "       Trigger a reset of one or more GPUs.  Can be used to clear GPU  HW  and\n",
            "       SW  state  in situations that would otherwise require a machine reboot.\n",
            "       Typically useful if a double bit ECC error has occurred.   Optional  _\b-_\bi\n",
            "       switch  can  be  used  to target one or more specific devices.  Without\n",
            "       this option, all GPUs are reset.  Requires root.  There  can't  be  any\n",
            "       applications  using  these  devices  (e.g.  CUDA  application, graphics\n",
            "       application like X server, monitoring application like  other  instance\n",
            "       of  nvidia-smi).   There also can't be any compute applications running\n",
            "       on any other GPU in the system.\n",
            "\n",
            "       Starting with the NVIDIA Ampere architecture, GPUs with NVLink  connec‐\n",
            "       tions  can  be individually reset.  On NVSwitch systems, Fabric Manager\n",
            "       is required to facilitate reset.\n",
            "\n",
            "       If Fabric Manager is not running, or if any of the GPUs being reset are\n",
            "       based  on an architecture preceding the NVIDIA Ampere architecture, any\n",
            "       GPUs with NVLink connections to a GPU being reset must also be reset in\n",
            "       the  same  command.  This can be done either by omitting the _\b-_\bi switch,\n",
            "       or using the _\b-_\bi switch to specify the GPUs to  be  reset.   If  the  _\b-_\bi\n",
            "       option  does  not  specify a complete set of NVLink GPUs to reset, this\n",
            "       command will issue an error identifying the additional GPUs  that  must\n",
            "       be included in the reset command.\n",
            "\n",
            "       GPU reset is not guaranteed to work in all cases. It is not recommended\n",
            "       for production environments at this time.  In some situations there may\n",
            "       be  HW  components  on the board that fail to revert back to an initial\n",
            "       state following the reset request.  This is more likely to be  seen  on\n",
            "       Fermi-generation products vs. Kepler, and more likely to be seen if the\n",
            "       reset is being performed on a hung GPU.\n",
            "\n",
            "       Following a reset, it is recommended that the health of each reset  GPU\n",
            "       be  verified  before further use.  If any GPU is not healthy a complete\n",
            "       reset should be instigated by power cycling the node.\n",
            "\n",
            "       GPU reset operation will not be supported on MIG enabled vGPU guests.\n",
            "\n",
            "       Visit _\bh_\bt_\bt_\bp_\b:_\b/_\b/_\bd_\be_\bv_\be_\bl_\bo_\bp_\be_\br_\b._\bn_\bv_\bi_\bd_\bi_\ba_\b._\bc_\bo_\bm_\b/_\bg_\bp_\bu_\b-_\bd_\be_\bp_\bl_\bo_\by_\bm_\be_\bn_\bt_\b-_\bk_\bi_\bt  to  download  the\n",
            "       GDK.\n",
            "\n",
            "   -\b-l\blg\bgc\bc,\b, -\b--\b-l\blo\boc\bck\bk-\b-g\bgp\bpu\bu-\b-c\bcl\blo\boc\bck\bks\bs=\b=M\bMI\bIN\bN_\b_G\bGP\bPU\bU_\b_C\bCL\bLO\bOC\bCK\bK,\b,M\bMA\bAX\bX_\b_G\bGP\bPU\bU_\b_C\bCL\bLO\bOC\bCK\bK\n",
            "       Specifies  <minGpuClock,maxGpuClock>  clocks as a pair (e.g. 1500,1500)\n",
            "       that defines closest desired locked GPU clock speed in MHz.  Input  can\n",
            "       also  use  be  a  singular  desired clock value (e.g. <GpuClockValue>).\n",
            "       Supported on Volta+.  Requires root\n",
            "\n",
            "   -\b-r\brg\bgc\bc,\b, -\b--\b-r\bre\bes\bse\bet\bt-\b-g\bgp\bpu\bu-\b-c\bcl\blo\boc\bck\bks\bs\n",
            "       Resets the GPU clocks to  the  default  value.   Supported  on  Volta+.\n",
            "       Requires root.\n",
            "\n",
            "   -\b-a\bac\bc,\b, -\b--\b-a\bap\bpp\bpl\bli\bic\bca\bat\bti\bio\bon\bns\bs-\b-c\bcl\blo\boc\bck\bks\bs=\b=M\bME\bEM\bM_\b_C\bCL\bLO\bOC\bCK\bK,\b,G\bGR\bRA\bAP\bPH\bHI\bIC\bCS\bS_\b_C\bCL\bLO\bOC\bCK\bK\n",
            "       Specifies  maximum  <memory,graphics>  clocks as a pair (e.g. 2000,800)\n",
            "       that defines GPU's speed while running applications  on  a  GPU.   Sup‐\n",
            "       ported  on  Maxwell-based  GeForce  and  from  the  Kepler+  family  in\n",
            "       Tesla/Quadro/Titan devices.  Requires root.\n",
            "\n",
            "   -\b-r\bra\bac\bc,\b, -\b--\b-r\bre\bes\bse\bet\bt-\b-a\bap\bpp\bpl\bli\bic\bca\bat\bti\bio\bon\bns\bs-\b-c\bcl\blo\boc\bck\bks\bs\n",
            "       Resets the applications clocks to the default value.  Supported on Max‐\n",
            "       well-based  GeForce  and  from the Kepler+ family in Tesla/Quadro/Titan\n",
            "       devices.  Requires root.\n",
            "\n",
            "   -\b-p\bpl\bl,\b, -\b--\b-p\bpo\bow\bwe\ber\br-\b-l\bli\bim\bmi\bit\bt=\b=P\bPO\bOW\bWE\bER\bR_\b_L\bLI\bIM\bMI\bIT\bT\n",
            "       Specifies maximum power limit in watts.  Accepts integer  and  floating\n",
            "       point numbers.  Only on supported devices from Kepler family.  Requires\n",
            "       administrator privileges.  Value needs to be between Min and Max  Power\n",
            "       Limit as reported by nvidia-smi.\n",
            "\n",
            "   -\b-c\bcc\bc,\b, -\b--\b-c\bcu\bud\bda\ba-\b-c\bcl\blo\boc\bck\bks\bs=\b=M\bMO\bOD\bDE\bE\n",
            "       Overrides  or  restores  default  CUDA  clocks  Available arguments are\n",
            "       0|RESTORE_DEFAULT or 1|OVERRIDE.\n",
            "\n",
            "   -\b-a\bam\bm,\b, -\b--\b-a\bac\bcc\bco\bou\bun\bnt\bti\bin\bng\bg-\b-m\bmo\bod\bde\be=\b=M\bMO\bOD\bDE\bE\n",
            "       Enables or disables GPU Accounting.  With GPU Accounting one  can  keep\n",
            "       track  of  usage  of resources throughout lifespan of a single process.\n",
            "       Only on supported devices from Kepler family.   Requires  administrator\n",
            "       privileges.  Available arguments are 0|DISABLED or 1|ENABLED.\n",
            "\n",
            "   -\b-c\bca\baa\ba,\b, -\b--\b-c\bcl\ble\bea\bar\br-\b-a\bac\bcc\bco\bou\bun\bnt\bte\bed\bd-\b-a\bap\bpp\bps\bs\n",
            "       Clears  all processes accounted so far.  Only on supported devices from\n",
            "       Kepler family.  Requires administrator privileges.\n",
            "\n",
            "        -\b--\b-a\bau\but\bto\bo-\b-b\bbo\boo\bos\bst\bt-\b-d\bde\bef\bfa\bau\bul\blt\bt=\b=M\bMO\bOD\bDE\bE\n",
            "       Set the default auto boost policy to 0/DISABLED or 1/ENABLED, enforcing\n",
            "       the  change  only after the last boost client has exited.  Only on cer‐\n",
            "       tain Tesla devices from the Kepler+ family  and  Maxwell-based  GeForce\n",
            "       devices.  Requires root.\n",
            "\n",
            "        -\b--\b-a\bau\but\bto\bo-\b-b\bbo\boo\bos\bst\bt-\b-d\bde\bef\bfa\bau\bul\blt\bt-\b-f\bfo\bor\brc\bce\be=\b=M\bMO\bOD\bDE\bE\n",
            "       Set the default auto boost policy to 0/DISABLED or 1/ENABLED, enforcing\n",
            "       the change immediately.  Only on certain Tesla devices from the Kepler+\n",
            "       family and Maxwell-based GeForce devices.  Requires root.\n",
            "\n",
            "        -\b--\b-a\bau\but\bto\bo-\b-b\bbo\boo\bos\bst\bt-\b-p\bpe\ber\brm\bmi\bis\bss\bsi\bio\bon\bn=\b=M\bMO\bOD\bDE\bE\n",
            "       Allow non-admin/root control over auto boost mode.  Available arguments\n",
            "       are 0|UNRESTRICTED, 1|RESTRICTED.  Only on certain Tesla  devices  from\n",
            "       the Kepler+ family and Maxwell-based GeForce devices.  Requires root.\n",
            "\n",
            "   -\b-m\bmi\big\bg,\b, -\b--\b-m\bmu\bul\blt\bti\bi-\b-i\bin\bns\bst\bta\ban\bnc\bce\be-\b-g\bgp\bpu\bu=\b=M\bMO\bOD\bDE\bE\n",
            "       Enables or disables Multi Instance GPU mode.  Only supported on devices\n",
            "       based on the NVIDIA Ampere  architecture.   Requires  root.   Available\n",
            "       arguments are 0|DISABLED or 1|ENABLED.\n",
            "\n",
            "   [\b[p\bpl\blu\bus\bs o\bop\bpt\bti\bio\bon\bna\bal\bl]\b]\n",
            "   -\b-i\bi,\b, -\b--\b-i\bid\bd=\b=I\bID\bD\n",
            "       Modify  a single specified GPU.  The specified id may be the GPU/Unit's\n",
            "       0-based index in the natural enumeration returned by  the  driver,  the\n",
            "       GPU's  board serial number, the GPU's UUID, or the GPU's PCI bus ID (as\n",
            "       domain:bus:device.function in  hex).   It  is  recommended  that  users\n",
            "       desiring  consistency  use either UUID or PCI bus ID, since device enu‐\n",
            "       meration ordering is not guaranteed to be  consistent  between  reboots\n",
            "       and  board  serial  number might be shared between multiple GPUs on the\n",
            "       same board.\n",
            "\n",
            "   U\bUN\bNI\bIT\bT M\bMO\bOD\bDI\bIF\bFI\bIC\bCA\bAT\bTI\bIO\bON\bN O\bOP\bPT\bTI\bIO\bON\bNS\bS\n",
            "   -\b-t\bt,\b, -\b--\b-t\bto\bog\bgg\bgl\ble\be-\b-l\ble\bed\bd=\b=S\bST\bTA\bAT\bTE\bE\n",
            "       Set the LED indicator state on the front and back of the  unit  to  the\n",
            "       specified  color.   See the (_\bU_\bN_\bI_\bT _\bA_\bT_\bT_\bR_\bI_\bB_\bU_\bT_\bE_\bS) section for a description\n",
            "       of the LED states.  Allowed colors are 0|GREEN and  1|AMBER.   Requires\n",
            "       root.\n",
            "\n",
            "   [\b[p\bpl\blu\bus\bs o\bop\bpt\bti\bio\bon\bna\bal\bl]\b]\n",
            "   -\b-i\bi,\b, -\b--\b-i\bid\bd=\b=I\bID\bD\n",
            "       Modify a single specified Unit.  The specified id is the Unit's 0-based\n",
            "       index in the natural enumeration returned by the driver.\n",
            "\n",
            "   S\bSH\bHO\bOW\bW D\bDT\bTD\bD O\bOP\bPT\bTI\bIO\bON\bNS\bS\n",
            "   -\b--\b-d\bdt\btd\bd\n",
            "       Display Device or Unit DTD.\n",
            "\n",
            "   [\b[p\bpl\blu\bus\bs o\bop\bpt\bti\bio\bon\bna\bal\bl]\b]\n",
            "   -\b-f\bf F\bFI\bIL\bLE\bE,\b, -\b--\b-f\bfi\bil\ble\ben\bna\bam\bme\be=\b=F\bFI\bIL\bLE\bE\n",
            "       Redirect query output to the specified file in  place  of  the  default\n",
            "       stdout.  The specified file will be overwritten.\n",
            "\n",
            "   -\b-u\bu,\b, -\b--\b-u\bun\bni\bit\bt\n",
            "       Display Unit DTD instead of device DTD.\n",
            "\n",
            "   s\bst\bta\bat\bts\bs\n",
            "       Display  statistics  information  about the GPU.  Use \"nvidia-smi stats\n",
            "       -h\" for more information.  Linux only.\n",
            "\n",
            "   t\bto\bop\bpo\bo\n",
            "       Display topology information about the system.   Use  \"nvidia-smi  topo\n",
            "       -h\"  for more information.  Linux only.  Shows all GPUs NVML is able to\n",
            "       detect but CPU and NUMA node affinity information will  only  be  shown\n",
            "       for  GPUs with Kepler or newer architectures.  Note: GPU enumeration is\n",
            "       the same as NVML.\n",
            "\n",
            "   d\bdr\bra\bai\bin\bn\n",
            "       Display and modify the GPU drain states.  Use \"nvidia-smi drain -h\" for\n",
            "       more information. Linux only.\n",
            "\n",
            "   n\bnv\bvl\bli\bin\bnk\bk\n",
            "       Display nvlink information.  Use \"nvidia-smi nvlink -h\" for more infor‐\n",
            "       mation.\n",
            "\n",
            "   c\bcl\blo\boc\bck\bks\bs\n",
            "       Query and control clocking behavior. Currently, this only  pertains  to\n",
            "       synchronized  boost.  Use  \"nvidia-smi clocks --help\" for more informa‐\n",
            "       tion.\n",
            "\n",
            "   v\bvg\bgp\bpu\bu\n",
            "       Display information on GRID virtual GPUs. Use \"nvidia-smi vgpu -h\"  for\n",
            "       more information.\n",
            "\n",
            "   m\bmi\big\bg\n",
            "       Provides controls for MIG management.\n",
            "\n",
            "   b\bbo\boo\bos\bst\bt-\b-s\bsl\bli\bid\bde\ber\br\n",
            "       Provides controls for boost sliders management.\n",
            "\n",
            "   p\bpo\bow\bwe\ber\br-\b-h\bhi\bin\bnt\bt\n",
            "       Provides queries for power hint.\n",
            "\n",
            "R\bRE\bET\bTU\bUR\bRN\bN V\bVA\bAL\bLU\bUE\bE\n",
            "       Return code reflects whether the operation succeeded or failed and what\n",
            "       was the reason of failure.\n",
            "\n",
            "       ·      Return code 0 - Success\n",
            "\n",
            "       ·      Return code 2 - A supplied argument or flag is invalid\n",
            "\n",
            "       ·      Return code 3 - The requested operation is not available on tar‐\n",
            "              get device\n",
            "\n",
            "       ·      Return  code  4  -  The current user does not have permission to\n",
            "              access this device or perform this operation\n",
            "\n",
            "       ·      Return code 6 - A query to find an object was unsuccessful\n",
            "\n",
            "       ·      Return code 8 - A device's external power cables are  not  prop‐\n",
            "              erly attached\n",
            "\n",
            "       ·      Return code 9 - NVIDIA driver is not loaded\n",
            "\n",
            "       ·      Return  code 10 - NVIDIA Kernel detected an interrupt issue with\n",
            "              a GPU\n",
            "\n",
            "       ·      Return code 12 - NVML Shared Library couldn't be found or loaded\n",
            "\n",
            "       ·      Return code 13 - Local version of NVML  doesn't  implement  this\n",
            "              function\n",
            "\n",
            "       ·      Return code 14 - infoROM is corrupted\n",
            "\n",
            "       ·      Return code 15 - The GPU has fallen off the bus or has otherwise\n",
            "              become inaccessible\n",
            "\n",
            "       ·      Return code 255 - Other error or internal driver error occurred\n",
            "\n",
            "G\bGP\bPU\bU A\bAT\bTT\bTR\bRI\bIB\bBU\bUT\bTE\bES\bS\n",
            "       The following list describes all  possible  data  returned  by  the  -\b-q\bq\n",
            "       device  query option.  Unless otherwise noted all numerical results are\n",
            "       base 10 and unitless.\n",
            "\n",
            "   T\bTi\bim\bme\bes\bst\bta\bam\bmp\bp\n",
            "       The current system timestamp at the time nvidia-smi was invoked.   For‐\n",
            "       mat is \"Day-of-week Month Day HH:MM:SS Year\".\n",
            "\n",
            "   D\bDr\bri\biv\bve\ber\br V\bVe\ber\brs\bsi\bio\bon\bn\n",
            "       The  version  of  the  installed  NVIDIA  display  driver.   This is an\n",
            "       alphanumeric string.\n",
            "\n",
            "   A\bAt\btt\bta\bac\bch\bhe\bed\bd G\bGP\bPU\bUs\bs\n",
            "       The number of NVIDIA GPUs in the system.\n",
            "\n",
            "   P\bPr\bro\bod\bdu\buc\bct\bt N\bNa\bam\bme\be\n",
            "       The official product name of the GPU.  This is an alphanumeric  string.\n",
            "       For all products.\n",
            "\n",
            "   D\bDi\bis\bsp\bpl\bla\bay\by M\bMo\bod\bde\be\n",
            "       A flag that indicates whether a physical display (e.g. monitor) is cur‐\n",
            "       rently connected to any of the GPU's connectors.   \"Enabled\"  indicates\n",
            "       an attached display.  \"Disabled\" indicates otherwise.\n",
            "\n",
            "   D\bDi\bis\bsp\bpl\bla\bay\by A\bAc\bct\bti\biv\bve\be\n",
            "       A  flag  that  indicates  whether a display is initialized on the GPU's\n",
            "       (e.g. memory is allocated on the device for display).  Display  can  be\n",
            "       active  even  when  no monitor is physically attached.  \"Enabled\" indi‐\n",
            "       cates an active display.  \"Disabled\" indicates otherwise.\n",
            "\n",
            "   P\bPe\ber\brs\bsi\bis\bst\bte\ben\bnc\bce\be M\bMo\bod\bde\be\n",
            "       A flag that indicates whether persistence mode is enabled for the  GPU.\n",
            "       Value  is  either  \"Enabled\"  or  \"Disabled\".  When persistence mode is\n",
            "       enabled the NVIDIA driver remains loaded even when no  active  clients,\n",
            "       such  as  X11  or  nvidia-smi,  exist.   This minimizes the driver load\n",
            "       latency associated with running dependent apps, such as CUDA  programs.\n",
            "       For all CUDA-capable products.  Linux only.\n",
            "\n",
            "   A\bAc\bcc\bco\bou\bun\bnt\bti\bin\bng\bg M\bMo\bod\bde\be\n",
            "       A  flag  that  indicates whether accounting mode is enabled for the GPU\n",
            "       Value is either When accounting is enabled  statistics  are  calculated\n",
            "       for each compute process running on the GPU.  Statistics can be queried\n",
            "       during the lifetime or after termination of the process. The  execution\n",
            "       time  of process is reported as 0 while the process is in running state\n",
            "       and updated to actual execution time after the process has  terminated.\n",
            "       See --help-query-accounted-apps for more info.\n",
            "\n",
            "   A\bAc\bcc\bco\bou\bun\bnt\bti\bin\bng\bg M\bMo\bod\bde\be B\bBu\buf\bff\bfe\ber\br S\bSi\biz\bze\be\n",
            "       Returns  the  size  of the circular buffer that holds list of processes\n",
            "       that can be queried for accounting stats.  This is the  maximum  number\n",
            "       of  processes  that  accounting  information  will be stored for before\n",
            "       information about oldest processes will get overwritten by  information\n",
            "       about new processes.\n",
            "\n",
            "   D\bDr\bri\biv\bve\ber\br M\bMo\bod\bde\bel\bl\n",
            "       On  Windows,  the TCC and WDDM driver models are supported.  The driver\n",
            "       model can be changed with the (_\b-_\bd_\bm) or (_\b-_\bf_\bd_\bm) flags.   The  TCC  driver\n",
            "       model  is optimized for compute applications.  I.E. kernel launch times\n",
            "       will be quicker with TCC.  The WDDM driver model is designed for graph‐\n",
            "       ics  applications  and  is  not  recommended  for compute applications.\n",
            "       Linux does not support multiple driver models, and will always have the\n",
            "       value of \"N/A\".\n",
            "\n",
            "       C\bCu\bur\brr\bre\ben\bnt\bt        The  driver  model  currently  in  use.  Always \"N/A\" on\n",
            "                      Linux.\n",
            "\n",
            "       P\bPe\ben\bnd\bdi\bin\bng\bg        The driver model that will be used on the  next  reboot.\n",
            "                      Always \"N/A\" on Linux.\n",
            "\n",
            "   S\bSe\ber\bri\bia\bal\bl N\bNu\bum\bmb\bbe\ber\br\n",
            "       This number matches the serial number physically printed on each board.\n",
            "       It is a globally unique immutable alphanumeric value.\n",
            "\n",
            "   G\bGP\bPU\bU U\bUU\bUI\bID\bD\n",
            "       This value is the globally unique immutable alphanumeric identifier  of\n",
            "       the GPU.  It does not correspond to any physical label on the board.\n",
            "\n",
            "   M\bMi\bin\bno\bor\br N\bNu\bum\bmb\bbe\ber\br\n",
            "       The  minor  number  for  the device is such that the Nvidia device node\n",
            "       file for each GPU will have the form /dev/nvidia[minor number].  Avail‐\n",
            "       able only on Linux platform.\n",
            "\n",
            "   V\bVB\bBI\bIO\bOS\bS V\bVe\ber\brs\bsi\bio\bon\bn\n",
            "       The BIOS of the GPU board.\n",
            "\n",
            "   M\bMu\bul\blt\bti\biG\bGP\bPU\bU B\bBo\boa\bar\brd\bd\n",
            "       Whether or not this GPU is part of a multiGPU board.\n",
            "\n",
            "   B\bBo\boa\bar\brd\bd I\bID\bD\n",
            "       The  unique  board ID assigned by the driver.  If two or more GPUs have\n",
            "       the same board ID and the above \"MultiGPU\" field is true then the  GPUs\n",
            "       are on the same board.\n",
            "\n",
            "   I\bIn\bnf\bfo\bor\bro\bom\bm V\bVe\ber\brs\bsi\bio\bon\bn\n",
            "       Version  numbers  for  each  object in the GPU board's inforom storage.\n",
            "       The inforom is a small, persistent store  of  configuration  and  state\n",
            "       data for the GPU.  All inforom version fields are numerical.  It can be\n",
            "       useful to know these version numbers because some GPU features are only\n",
            "       available with inforoms of a certain version or higher.\n",
            "\n",
            "       If any of the fields below return Unknown Error additional Inforom ver‐\n",
            "       ification check is performed and appropriate warning  message  is  dis‐\n",
            "       played.\n",
            "\n",
            "       I\bIm\bma\bag\bge\be V\bVe\ber\brs\bsi\bio\bon\bn  Global version of the infoROM image.  Image version just\n",
            "                      like VBIOS version uniquely describes the exact  version\n",
            "                      of  the  infoROM  flashed  on  the  board in contrast to\n",
            "                      infoROM object version which is  only  an  indicator  of\n",
            "                      supported features.\n",
            "\n",
            "       O\bOE\bEM\bM O\bOb\bbj\bje\bec\bct\bt     Version for the OEM configuration data.\n",
            "\n",
            "       E\bEC\bCC\bC O\bOb\bbj\bje\bec\bct\bt     Version for the ECC recording data.\n",
            "\n",
            "       P\bPo\bow\bwe\ber\br O\bOb\bbj\bje\bec\bct\bt   Version for the power management data.\n",
            "\n",
            "   G\bGP\bPU\bU O\bOp\bpe\ber\bra\bat\bti\bio\bon\bn M\bMo\bod\bde\be\n",
            "       GOM  allows  to  reduce power usage and optimize GPU throughput by dis‐\n",
            "       abling GPU features.\n",
            "\n",
            "       Each GOM is designed to meet specific user needs.\n",
            "\n",
            "       In \"All On\" mode everything is enabled and running at full speed.\n",
            "\n",
            "       The \"Compute\" mode is designed for running only compute tasks. Graphics\n",
            "       operations are not allowed.\n",
            "\n",
            "       The \"Low Double Precision\" mode is designed for running graphics appli‐\n",
            "       cations that don't require high bandwidth double precision.\n",
            "\n",
            "       GOM can be changed with the (_\b-_\b-_\bg_\bo_\bm) flag.\n",
            "\n",
            "       Supported on GK110 M-class and X-class Tesla products from  the  Kepler\n",
            "       family.   Not supported on Quadro and Tesla C-class products.  Low Dou‐\n",
            "       ble Precision and All On modes are the only modes  available  for  sup‐\n",
            "       ported GeForce Titan products.\n",
            "\n",
            "       C\bCu\bur\brr\bre\ben\bnt\bt        The GOM currently in use.\n",
            "\n",
            "       P\bPe\ben\bnd\bdi\bin\bng\bg        The GOM that will be used on the next reboot.\n",
            "\n",
            "   P\bPC\bCI\bI\n",
            "       Basic  PCI  info  for  the device.  Some of this information may change\n",
            "       whenever cards are added/removed/moved in a system.  For all products.\n",
            "\n",
            "       B\bBu\bus\bs            PCI bus number, in hex\n",
            "\n",
            "       D\bDe\bev\bvi\bic\bce\be         PCI device number, in hex\n",
            "\n",
            "       D\bDo\bom\bma\bai\bin\bn         PCI domain number, in hex\n",
            "\n",
            "       D\bDe\bev\bvi\bic\bce\be I\bId\bd      PCI vendor device id, in hex\n",
            "\n",
            "       S\bSu\bub\bb S\bSy\bys\bst\bte\bem\bm I\bId\bd  PCI Sub System id, in hex\n",
            "\n",
            "       B\bBu\bus\bs I\bId\bd         PCI bus id as \"domain:bus:device.function\", in hex\n",
            "\n",
            "   G\bGP\bPU\bU L\bLi\bin\bnk\bk i\bin\bnf\bfo\bor\brm\bma\bat\bti\bio\bon\bn\n",
            "       The PCIe link generation and bus width\n",
            "\n",
            "       C\bCu\bur\brr\bre\ben\bnt\bt        The current link generation and  width.   These  may  be\n",
            "                      reduced when the GPU is not in use.\n",
            "\n",
            "       M\bMa\bax\bxi\bim\bmu\bum\bm        The maximum link generation and width possible with this\n",
            "                      GPU and system configuration.  For example, if  the  GPU\n",
            "                      supports  a  higher PCIe generation than the system sup‐\n",
            "                      ports then this reports the system PCIe generation.\n",
            "\n",
            "   B\bBr\bri\bid\bdg\bge\be C\bCh\bhi\bip\bp\n",
            "       Information related to Bridge Chip  on  the  device.  The  bridge  chip\n",
            "       firmware  is  only  present on certain boards and may display \"N/A\" for\n",
            "       some newer multiGPUs boards.\n",
            "\n",
            "       T\bTy\byp\bpe\be           The type of bridge chip.  Reported  as  N/A  if  doesn't\n",
            "                      exist.\n",
            "\n",
            "       F\bFi\bir\brm\bmw\bwa\bar\bre\be V\bVe\ber\brs\bsi\bio\bon\bn\n",
            "                      The firmware version of the bridge chip. Reported as N/A\n",
            "                      if doesn't exist.\n",
            "\n",
            "   R\bRe\bep\bpl\bla\bay\bys\bs S\bSi\bin\bnc\bce\be R\bRe\bes\bse\bet\bt\n",
            "       The number of PCIe replays since reset.\n",
            "\n",
            "   R\bRe\bep\bpl\bla\bay\by N\bNu\bum\bmb\bbe\ber\br R\bRo\bol\bll\blo\bov\bve\ber\brs\bs\n",
            "       The number of PCIe replay number rollovers since reset. A replay number\n",
            "       rollover  occurs  after 4 consecutive replays and results in retraining\n",
            "       the link.\n",
            "\n",
            "   T\bTx\bx T\bTh\bhr\bro\bou\bug\bgh\bhp\bpu\but\bt\n",
            "       The GPU-centric transmission throughput across the  PCIe  bus  in  MB/s\n",
            "       over the past 20ms.  Only supported on Maxwell architectures and newer.\n",
            "\n",
            "   R\bRx\bx T\bTh\bhr\bro\bou\bug\bgh\bhp\bpu\but\bt\n",
            "       The GPU-centric receive throughput across the PCIe bus in MB/s over the\n",
            "       past 20ms.  Only supported on Maxwell architectures and newer.\n",
            "\n",
            "   F\bFa\ban\bn S\bSp\bpe\bee\bed\bd\n",
            "       The fan speed value is the percent of the product's maximum noise  tol‐\n",
            "       erance fan speed that the device's fan is currently intended to run at.\n",
            "       This value may exceed 100% in certain cases.  Note: The reported  speed\n",
            "       is the intended fan speed.  If the fan is physically blocked and unable\n",
            "       to spin, this output will not match the actual fan speed.   Many  parts\n",
            "       do  not  report fan speeds because they rely on cooling via fans in the\n",
            "       surrounding enclosure.  For all discrete products with dedicated fans.\n",
            "\n",
            "   P\bPe\ber\brf\bfo\bor\brm\bma\ban\bnc\bce\be S\bSt\bta\bat\bte\be\n",
            "       The current performance state for the GPU.  States range from P0 (maxi‐\n",
            "       mum performance) to P12 (minimum performance).\n",
            "\n",
            "   C\bCl\blo\boc\bck\bks\bs T\bTh\bhr\bro\bot\btt\btl\ble\be R\bRe\bea\bas\bso\bon\bns\bs\n",
            "       Retrieves  information about factors that are reducing the frequency of\n",
            "       clocks.\n",
            "\n",
            "       If all throttle reasons are returned as  \"Not  Active\"  it  means  that\n",
            "       clocks are running as high as possible.\n",
            "\n",
            "       I\bId\bdl\ble\be           Nothing  is  running on the GPU and the clocks are drop‐\n",
            "                      ping to Idle state.  This limiter may be  removed  in  a\n",
            "                      later release.\n",
            "\n",
            "       A\bAp\bpp\bpl\bli\bic\bca\bat\bti\bio\bon\bn C\bCl\blo\boc\bck\bks\bs S\bSe\bet\btt\bti\bin\bng\bg\n",
            "                      GPU  clocks  are limited by applications clocks setting.\n",
            "                      E.g.  can  be  changed   using   nvidia-smi   --applica‐\n",
            "                      tions-clocks=\n",
            "\n",
            "       S\bSW\bW P\bPo\bow\bwe\ber\br C\bCa\bap\bp   SW  Power Scaling algorithm is reducing the clocks below\n",
            "                      requested clocks because the GPU is consuming  too  much\n",
            "                      power.   E.g.  SW  power  cap  limit can be changed with\n",
            "                      nvidia-smi --power-limit=\n",
            "\n",
            "       H\bHW\bW S\bSl\blo\bow\bwd\bdo\bow\bwn\bn    HW Slowdown (reducing the core clocks by a factor  of  2\n",
            "                      or  more)  is engaged.  HW Thermal Slowdown and HW Power\n",
            "                      Brake will be displayed on Pascal+.\n",
            "\n",
            "                      This is an indicator of:\n",
            "                      * Temperature being too high (HW Thermal Slowdown)\n",
            "                      * External Power Brake Assertion is triggered  (e.g.  by\n",
            "                      the system power supply) (HW Power Brake Slowdown)\n",
            "                      *  Power draw is too high and Fast Trigger protection is\n",
            "                      reducing the clocks\n",
            "\n",
            "       S\bSW\bW T\bTh\bhe\ber\brm\bma\bal\bl S\bSl\blo\bow\bwd\bdo\bow\bwn\bn\n",
            "                      SW Thermal capping algorithm is  reducing  clocks  below\n",
            "                      requested  clocks because GPU temperature is higher than\n",
            "                      Max Operating Temp\n",
            "\n",
            "   F\bFB\bB M\bMe\bem\bmo\bor\bry\by U\bUs\bsa\bag\bge\be\n",
            "       On-board frame buffer memory information.   Reported  total  memory  is\n",
            "       affected by ECC state.  If ECC is enabled the total available memory is\n",
            "       decreased by several percent, due to the requisite  parity  bits.   The\n",
            "       driver may also reserve a small amount of memory for internal use, even\n",
            "       without active work on the GPU.  For all products.\n",
            "\n",
            "       T\bTo\bot\bta\bal\bl          Total size of FB memory.\n",
            "\n",
            "       U\bUs\bse\bed\bd           Used size of FB memory.\n",
            "\n",
            "       F\bFr\bre\bee\be           Available size of FB memory.\n",
            "\n",
            "   B\bBA\bAR\bR1\b1 M\bMe\bem\bmo\bor\bry\by U\bUs\bsa\bag\bge\be\n",
            "       BAR1 is used to map the FB (device memory) so that it can  be  directly\n",
            "       accessed  by  the CPU or by 3rd party devices (peer-to-peer on the PCIe\n",
            "       bus).\n",
            "\n",
            "       T\bTo\bot\bta\bal\bl          Total size of BAR1 memory.\n",
            "\n",
            "       U\bUs\bse\bed\bd           Used size of BAR1 memory.\n",
            "\n",
            "       F\bFr\bre\bee\be           Available size of BAR1 memory.\n",
            "\n",
            "   C\bCo\bom\bmp\bpu\but\bte\be M\bMo\bod\bde\be\n",
            "       The compute mode flag indicates whether individual or multiple  compute\n",
            "       applications may run on the GPU.\n",
            "\n",
            "       \"Default\" means multiple contexts are allowed per device.\n",
            "\n",
            "       \"Exclusive  Process\"  means  only  one  context  is allowed per device,\n",
            "       usable from multiple threads at a time.\n",
            "\n",
            "       \"Prohibited\" means no contexts  are  allowed  per  device  (no  compute\n",
            "       apps).\n",
            "\n",
            "       \"EXCLUSIVE_PROCESS\"  was  added  in CUDA 4.0.  Prior CUDA releases sup‐\n",
            "       ported  only  one  exclusive  mode,  which  is  equivalent  to  \"EXCLU‐\n",
            "       SIVE_THREAD\" in CUDA 4.0 and beyond.\n",
            "\n",
            "       For all CUDA-capable products.\n",
            "\n",
            "   U\bUt\bti\bil\bli\biz\bza\bat\bti\bio\bon\bn\n",
            "       Utilization  rates  report  how  busy each GPU is over time, and can be\n",
            "       used to determine how much an application is using the GPUs in the sys‐\n",
            "       tem.\n",
            "\n",
            "       Note: During driver initialization when ECC is enabled one can see high\n",
            "       GPU and Memory Utilization readings.  This  is  caused  by  ECC  Memory\n",
            "       Scrubbing mechanism that is performed during driver initialization.\n",
            "\n",
            "       G\bGP\bPU\bU            Percent of time over the past sample period during which\n",
            "                      one or more kernels was executing on the GPU.  The  sam‐\n",
            "                      ple  period  may  be  between  1  second  and 1/6 second\n",
            "                      depending on the product.\n",
            "\n",
            "       M\bMe\bem\bmo\bor\bry\by         Percent of time over the past sample period during which\n",
            "                      global  (device)  memory was being read or written.  The\n",
            "                      sample period may be between 1  second  and  1/6  second\n",
            "                      depending on the product.\n",
            "\n",
            "       E\bEn\bnc\bco\bod\bde\ber\br        Percent of time over the past sample period during which\n",
            "                      the GPU's video encoder was being  used.   The  sampling\n",
            "                      rate  is  variable  and can be obtained directly via the\n",
            "                      nvmlDeviceGetEncoderUtilization() API\n",
            "\n",
            "       D\bDe\bec\bco\bod\bde\ber\br        Percent of time over the past sample period during which\n",
            "                      the  GPU's  video  decoder was being used.  The sampling\n",
            "                      rate is variable and can be obtained  directly  via  the\n",
            "                      nvmlDeviceGetDecoderUtilization() API\n",
            "\n",
            "   E\bEc\bcc\bc M\bMo\bod\bde\be\n",
            "       A  flag  that  indicates whether ECC support is enabled.  May be either\n",
            "       \"Enabled\" or  \"Disabled\".   Changes  to  ECC  mode  require  a  reboot.\n",
            "       Requires Inforom ECC object version 1.0 or higher.\n",
            "\n",
            "       C\bCu\bur\brr\bre\ben\bnt\bt        The ECC mode that the GPU is currently operating under.\n",
            "\n",
            "       P\bPe\ben\bnd\bdi\bin\bng\bg        The  ECC  mode that the GPU will operate under after the\n",
            "                      next reboot.\n",
            "\n",
            "   E\bEC\bCC\bC E\bEr\brr\bro\bor\brs\bs\n",
            "       NVIDIA GPUs can provide error counts for various types of  ECC  errors.\n",
            "       Some  ECC  errors  are  either  single  or double bit, where single bit\n",
            "       errors are corrected and double bit errors are uncorrectable.   Texture\n",
            "       memory  errors  may  be  correctable via resend or uncorrectable if the\n",
            "       resend  fails.   These  errors  are  available  across  two  timescales\n",
            "       (volatile and aggregate).  Single bit ECC errors are automatically cor‐\n",
            "       rected by the HW and do not result  in  data  corruption.   Double  bit\n",
            "       errors are detected but not corrected.  Please see the ECC documents on\n",
            "       the web for information on compute application behavior when double bit\n",
            "       errors  occur.   Volatile  error  counters  track  the number of errors\n",
            "       detected since the last driver load.  Aggregate  error  counts  persist\n",
            "       indefinitely and thus act as a lifetime counter.\n",
            "\n",
            "       A  note  about  volatile  counts: On Windows this is once per boot.  On\n",
            "       Linux this can be more frequent.  On Linux the driver unloads  when  no\n",
            "       active  clients  exist.  Hence, if persistence mode is enabled or there\n",
            "       is always a driver client active (e.g. X11), then Linux also sees  per-\n",
            "       boot  behavior.   If not, volatile counts are reset each time a compute\n",
            "       app is run.\n",
            "\n",
            "       Tesla and Quadro products from the Fermi and Kepler family can  display\n",
            "       total ECC error counts, as well as a breakdown of errors based on loca‐\n",
            "       tion on the chip.  The locations are described  below.   Location-based\n",
            "       data  for  aggregate  error  counts requires Inforom ECC object version\n",
            "       2.0.  All other ECC counts require ECC object version 1.0.\n",
            "\n",
            "       D\bDe\bev\bvi\bic\bce\be M\bMe\bem\bmo\bor\bry\by  Errors detected in global device memory.\n",
            "\n",
            "       R\bRe\beg\bgi\bis\bst\bte\ber\br F\bFi\bil\ble\be  Errors detected in register file memory.\n",
            "\n",
            "       L\bL1\b1 C\bCa\bac\bch\bhe\be       Errors detected in the L1 cache.\n",
            "\n",
            "       L\bL2\b2 C\bCa\bac\bch\bhe\be       Errors detected in the L2 cache.\n",
            "\n",
            "       T\bTe\bex\bxt\btu\bur\bre\be M\bMe\bem\bmo\bor\bry\by Parity errors detected in texture memory.\n",
            "\n",
            "       T\bTo\bot\bta\bal\bl          Total errors detected across entire chip. Sum of  D\bDe\bev\bvi\bic\bce\be\n",
            "                      M\bMe\bem\bmo\bor\bry\by,  R\bRe\beg\bgi\bis\bst\bte\ber\br  F\bFi\bil\ble\be,  L\bL1\b1 C\bCa\bac\bch\bhe\be, L\bL2\b2 C\bCa\bac\bch\bhe\be and T\bTe\bex\bxt\btu\bur\bre\be\n",
            "                      M\bMe\bem\bmo\bor\bry\by.\n",
            "\n",
            "   P\bPa\bag\bge\be R\bRe\bet\bti\bir\bre\bem\bme\ben\bnt\bt\n",
            "       NVIDIA GPUs can retire pages of GPU  device  memory  when  they  become\n",
            "       unreliable.   This can happen when multiple single bit ECC errors occur\n",
            "       for the same page, or on a double  bit  ECC  error.   When  a  page  is\n",
            "       retired,  the NVIDIA driver will hide it such that no driver, or appli‐\n",
            "       cation memory allocations can access it.\n",
            "\n",
            "       D\bDo\bou\bub\bbl\ble\be B\bBi\bit\bt E\bEC\bCC\bC The number of GPU device memory  pages  that  have  been\n",
            "       retired due to a double bit ECC error.\n",
            "\n",
            "       S\bSi\bin\bng\bgl\ble\be  B\bBi\bit\bt  E\bEC\bCC\bC  The  number of GPU device memory pages that have been\n",
            "       retired due to multiple single bit ECC errors.\n",
            "\n",
            "       P\bPe\ben\bnd\bdi\bin\bng\bg Checks if any GPU device memory pages are pending blacklist  on\n",
            "       the  next  reboot.   Pages that are retired but not yet blacklisted can\n",
            "       still be allocated, and may cause further reliability issues.\n",
            "\n",
            "   R\bRo\bow\bw R\bRe\bem\bma\bap\bpp\bpe\ber\br\n",
            "       NVIDIA GPUs can remap rows of GPU device memory when they become  unre‐\n",
            "       liable.   This can happen when a single uncorrectable ECC error or mul‐\n",
            "       tiple correctable ECC errors occur on the same  row.   When  a  row  is\n",
            "       remapped,  the  NVIDIA  driver  will remap the faulty row to a reserved\n",
            "       row.  All future accesses to the  row  will  access  the  reserved  row\n",
            "       instead of the faulty row.\n",
            "\n",
            "       C\bCo\bor\brr\bre\bec\bct\bta\bab\bbl\ble\be  E\bEr\brr\bro\bor\br  The  number  of rows that have been remapped due to\n",
            "       correctable ECC errors.\n",
            "\n",
            "       U\bUn\bnc\bco\bor\brr\bre\bec\bct\bta\bab\bbl\ble\be E\bEr\brr\bro\bor\br The number of rows that have been remapped  due  to\n",
            "       uncorrectable ECC errors.\n",
            "\n",
            "       P\bPe\ben\bnd\bdi\bin\bng\bg  Indicates  whether  or not a row is pending remapping. The GPU\n",
            "       must be reset for the remapping to go into effect.\n",
            "\n",
            "       R\bRe\bem\bma\bap\bpp\bpi\bin\bng\bg F\bFa\bai\bil\blu\bur\bre\be O\bOc\bcc\bcu\bur\brr\bre\bed\bd Indicates whether or not a row remapping has\n",
            "       failed in the past.\n",
            "\n",
            "       B\bBa\ban\bnk\bk  R\bRe\bem\bma\bap\bp  A\bAv\bva\bai\bil\bla\bab\bbi\bil\bli\bit\bty\by H\bHi\bis\bst\bto\bog\bgr\bra\bam\bm Each memory bank has a fixed number\n",
            "       of reserved rows that can be used for  row  remapping.   The  histogram\n",
            "       will  classify  the remap availability of each bank into Maximum, High,\n",
            "       Partial, Low and None.  Maximum availability means  that  all  reserved\n",
            "       rows are available for remapping while None means that no reserved rows\n",
            "       are available.\n",
            "\n",
            "   T\bTe\bem\bmp\bpe\ber\bra\bat\btu\bur\bre\be\n",
            "       Readings from temperature sensors on the board.  All  readings  are  in\n",
            "       degrees C.  Not all products support all reading types.  In particular,\n",
            "       products in module form factors that rely on case fans or passive cool‐\n",
            "       ing  do  not  usually  provide  temperature  readings.   See  below for\n",
            "       restrictions.\n",
            "\n",
            "       G\bGP\bPU\bU            Core GPU temperature.   For  all  discrete  and  S-class\n",
            "                      products.\n",
            "\n",
            "       S\bSh\bhu\but\btd\bdo\bow\bwn\bn T\bTe\bem\bmp\bp  The temperature at which a GPU will shutdown.\n",
            "\n",
            "       S\bSl\blo\bow\bwd\bdo\bow\bwn\bn T\bTe\bem\bmp\bp  The temperature at which a GPU will begin slowing itself\n",
            "                      down through HW, in order to cool.\n",
            "\n",
            "       M\bMa\bax\bx O\bOp\bpe\ber\bra\bat\bti\bin\bng\bg T\bTe\bem\bmp\bp\n",
            "                      The temperature at which a GPU will begin slowing itself\n",
            "                      down through SW, in order to cool.\n",
            "\n",
            "   P\bPo\bow\bwe\ber\br R\bRe\bea\bad\bdi\bin\bng\bgs\bs\n",
            "       Power  readings  help  to  shed light on the current power usage of the\n",
            "       GPU, and the factors that affect that usage.  When power management  is\n",
            "       enabled the GPU limits power draw under load to fit within a predefined\n",
            "       power envelope by manipulating  the  current  performance  state.   See\n",
            "       below  for limits of availability.  Please note that power readings are\n",
            "       not applicable for Pascal and higher GPUs with BA sensor boards.\n",
            "\n",
            "       P\bPo\bow\bwe\ber\br S\bSt\bta\bat\bte\be    Power State is deprecated and has been renamed  to  Per‐\n",
            "                      formance State in 2.285.  To maintain XML compatibility,\n",
            "                      in XML  format  Performance  State  is  listed  in  both\n",
            "                      places.\n",
            "\n",
            "       P\bPo\bow\bwe\ber\br M\bMa\ban\bna\bag\bge\bem\bme\ben\bnt\bt\n",
            "                      A  flag  that  indicates  whether  power  management  is\n",
            "                      enabled.  Either \"Supported\" or \"N/A\".  Requires Inforom\n",
            "                      PWR object version 3.0 or higher or Kepler device.\n",
            "\n",
            "       P\bPo\bow\bwe\ber\br D\bDr\bra\baw\bw     The  last  measured  power draw for the entire board, in\n",
            "                      watts.  Only available if power management is supported.\n",
            "                      Please  note  that  for boards without INA sensors, this\n",
            "                      refers to the power draw for the GPU  and  not  for  the\n",
            "                      entire board.\n",
            "\n",
            "       P\bPo\bow\bwe\ber\br L\bLi\bim\bmi\bit\bt    The  software  power  limit,  in watts.  Set by software\n",
            "                      such as nvidia-smi.  Only available if power  management\n",
            "                      is  supported.   Requires Inforom PWR object version 3.0\n",
            "                      or higher or Kepler device.   On  Kepler  devices  Power\n",
            "                      Limit can be adjusted using -pl,--power-limit= switches.\n",
            "\n",
            "       E\bEn\bnf\bfo\bor\brc\bce\bed\bd P\bPo\bow\bwe\ber\br L\bLi\bim\bmi\bit\bt\n",
            "                      The  power  management  algorithm's  power  ceiling,  in\n",
            "                      watts.  Total board power draw  is  manipulated  by  the\n",
            "                      power management algorithm such that it stays under this\n",
            "                      value.  This limit is the minimum of various limits such\n",
            "                      as  the  software limit listed above.  Only available if\n",
            "                      power  management  is  supported.   Requires  a   Kepler\n",
            "                      device.   Please  note  that for boards without INA sen‐\n",
            "                      sors, it is the GPU power draw  that  is  being  manipu‐\n",
            "                      lated.\n",
            "\n",
            "       D\bDe\bef\bfa\bau\bul\blt\bt P\bPo\bow\bwe\ber\br L\bLi\bim\bmi\bit\bt\n",
            "                      The  default power management algorithm's power ceiling,\n",
            "                      in watts.  Power Limit will be set back to Default Power\n",
            "                      Limit  after  driver  unload.  Only on supported devices\n",
            "                      from Kepler family.\n",
            "\n",
            "       M\bMi\bin\bn P\bPo\bow\bwe\ber\br L\bLi\bim\bmi\bit\bt\n",
            "                      The minimum value in watts that power limit can  be  set\n",
            "                      to.  Only on supported devices from Kepler family.\n",
            "\n",
            "       M\bMa\bax\bx P\bPo\bow\bwe\ber\br L\bLi\bim\bmi\bit\bt\n",
            "                      The  maximum  value in watts that power limit can be set\n",
            "                      to.  Only on supported devices from Kepler family.\n",
            "\n",
            "   C\bCl\blo\boc\bck\bks\bs\n",
            "       Current frequency at which parts of the GPU are running.  All  readings\n",
            "       are in MHz.\n",
            "\n",
            "       G\bGr\bra\bap\bph\bhi\bic\bcs\bs       Current frequency of graphics (shader) clock.\n",
            "\n",
            "       S\bSM\bM             Current   frequency  of  SM  (Streaming  Multiprocessor)\n",
            "                      clock.\n",
            "\n",
            "       M\bMe\bem\bmo\bor\bry\by         Current frequency of memory clock.\n",
            "\n",
            "       V\bVi\bid\bde\beo\bo          Current frequency of video (encoder + decoder) clocks.\n",
            "\n",
            "   A\bAp\bpp\bpl\bli\bic\bca\bat\bti\bio\bon\bns\bs C\bCl\blo\boc\bck\bks\bs\n",
            "       User specified frequency at which applications will be running at.  Can\n",
            "       be changed with [-ac | --applications-clocks] switches.\n",
            "\n",
            "       G\bGr\bra\bap\bph\bhi\bic\bcs\bs       User specified frequency of graphics (shader) clock.\n",
            "\n",
            "       M\bMe\bem\bmo\bor\bry\by         User specified frequency of memory clock.\n",
            "\n",
            "   D\bDe\bef\bfa\bau\bul\blt\bt A\bAp\bpp\bpl\bli\bic\bca\bat\bti\bio\bon\bns\bs C\bCl\blo\boc\bck\bks\bs\n",
            "       Default  frequency  at which applications will be running at.  Applica‐\n",
            "       tion clocks can be changed with [-ac | --applications-clocks] switches.\n",
            "       Application clocks can be set to default using [-rac | --reset-applica‐\n",
            "       tions-clocks] switches.\n",
            "\n",
            "       G\bGr\bra\bap\bph\bhi\bic\bcs\bs       Default  frequency  of  applications  graphics  (shader)\n",
            "                      clock.\n",
            "\n",
            "       M\bMe\bem\bmo\bor\bry\by         Default frequency of applications memory clock.\n",
            "\n",
            "   M\bMa\bax\bx C\bCl\blo\boc\bck\bks\bs\n",
            "       Maximum  frequency  at  which  parts of the GPU are design to run.  All\n",
            "       readings are in MHz.\n",
            "\n",
            "       On GPUs from Fermi family current P0 clocks (reported  in  Clocks  sec‐\n",
            "       tion) can differ from max clocks by few MHz.\n",
            "\n",
            "       G\bGr\bra\bap\bph\bhi\bic\bcs\bs       Maximum frequency of graphics (shader) clock.\n",
            "\n",
            "       S\bSM\bM             Maximum   frequency  of  SM  (Streaming  Multiprocessor)\n",
            "                      clock.\n",
            "\n",
            "       M\bMe\bem\bmo\bor\bry\by         Maximum frequency of memory clock.\n",
            "\n",
            "       V\bVi\bid\bde\beo\bo          Maximum frequency of video (encoder + decoder) clock.\n",
            "\n",
            "   C\bCl\blo\boc\bck\bk P\bPo\bol\bli\bic\bcy\by\n",
            "       User-specified settings for automated clocking  changes  such  as  auto\n",
            "       boost.\n",
            "\n",
            "       A\bAu\but\bto\bo B\bBo\boo\bos\bst\bt     Indicates  whether  auto boost mode is currently enabled\n",
            "                      for this GPU (On) or disabled for this GPU (Off).  Shows\n",
            "                      (N/A)  if  boost  is  not  supported.  Auto boost allows\n",
            "                      dynamic GPU clocking based on power,  thermal  and  uti‐\n",
            "                      lization.  When  auto  boost  is  disabled  the GPU will\n",
            "                      attempt to maintain  clocks  at  precisely  the  Current\n",
            "                      Application  Clocks settings (whenever a CUDA context is\n",
            "                      active). With auto boost  enabled  the  GPU  will  still\n",
            "                      attempt  to  maintain this floor, but will opportunisti‐\n",
            "                      cally boost to higher clocks  when  power,  thermal  and\n",
            "                      utilization  headroom  allow.  This setting persists for\n",
            "                      the life of the CUDA context for which it was requested.\n",
            "                      Apps  can  request  a particular mode either via an NVML\n",
            "                      call (see NVML SDK) or by setting the  CUDA  environment\n",
            "                      variable CUDA_AUTO_BOOST.\n",
            "\n",
            "       A\bAu\but\bto\bo B\bBo\boo\bos\bst\bt D\bDe\bef\bfa\bau\bul\blt\bt\n",
            "                      Indicates  the  default  setting  for  auto  boost mode,\n",
            "                      either enabled (On) or disabled (Off).  Shows  (N/A)  if\n",
            "                      boost  is  not  supported.  Apps will run in the default\n",
            "                      mode if they have not explicitly requested a  particular\n",
            "                      mode.  Note: Auto Boost settings can only be modified if\n",
            "                      \"Persistence Mode\" is enabled, which is NOT by default.\n",
            "\n",
            "   S\bSu\bup\bpp\bpo\bor\brt\bte\bed\bd c\bcl\blo\boc\bck\bks\bs\n",
            "       List of possible memory and graphics clocks combinations that  the  GPU\n",
            "       can  operate  on  (not  taking  into  account HW brake reduced clocks).\n",
            "       These are the only clock combinations that can be passed to  --applica‐\n",
            "       tions-clocks  flag.   Supported  Clocks are listed only when -q -d SUP‐\n",
            "       PORTED_CLOCKS switches are provided or in XML format.\n",
            "\n",
            "   V\bVo\bol\blt\bta\bag\bge\be\n",
            "       Current voltage reported by the GPU. All units are in mV.\n",
            "\n",
            "       G\bGr\bra\bap\bph\bhi\bic\bcs\bs       Current voltage of the graphics unit.\n",
            "\n",
            "   P\bPr\bro\boc\bce\bes\bss\bse\bes\bs\n",
            "       List of processes having Compute or Graphics  Context  on  the  device.\n",
            "       Compute  processes  are  reported  on all the fully supported products.\n",
            "       Reporting for Graphics processes is limited to the  supported  products\n",
            "       starting with Kepler architecture.\n",
            "\n",
            "       Each  Entry  is of format \"<GPU Index> <PID> <Type> <Process Name> <GPU\n",
            "       Memory Usage>\"\n",
            "\n",
            "       G\bGP\bPU\bU I\bIn\bnd\bde\bex\bx      Represents NVML Index of the device.\n",
            "\n",
            "       P\bPI\bID\bD            Represents Process ID corresponding to the  active  Com‐\n",
            "                      pute or Graphics context.\n",
            "\n",
            "       T\bTy\byp\bpe\be           Displayed  as  \"C\" for Compute Process, \"G\" for Graphics\n",
            "                      Process, and \"C+G\" for the process having  both  Compute\n",
            "                      and Graphics contexts.\n",
            "\n",
            "       P\bPr\bro\boc\bce\bes\bss\bs N\bNa\bam\bme\be   Represents  process  name  for  the  Compute or Graphics\n",
            "                      process.\n",
            "\n",
            "       G\bGP\bPU\bU M\bMe\bem\bmo\bor\bry\by U\bUs\bsa\bag\bge\be\n",
            "                      Amount of memory used on the device by the context.  Not\n",
            "                      available  on  Windows when running in WDDM mode because\n",
            "                      Windows KMD manages all the memory not NVIDIA driver.\n",
            "\n",
            "   S\bSt\bta\bat\bts\bs (\b(E\bEX\bXP\bPE\bER\bRI\bIM\bME\bEN\bNT\bTA\bAL\bL)\b)\n",
            "       List GPU statistics such as power  samples,  utilization  samples,  xid\n",
            "       events, clock change events and violation counters.\n",
            "\n",
            "       Supported on Tesla, GRID and Quadro based products under Linux.\n",
            "\n",
            "       Limited to Kepler or newer GPUs.\n",
            "\n",
            "       Displays statistics in CSV format as follows:\n",
            "\n",
            "       <GPU  device  index>,  <metric name>, <CPU Timestamp in us>, <value for\n",
            "       metric>\n",
            "\n",
            "       The metrics to display with their units are as follows:\n",
            "\n",
            "       Power samples in Watts.\n",
            "\n",
            "       GPU Temperature samples in degrees Celsius.\n",
            "\n",
            "       GPU, Memory, Encoder and Decoder utilization samples in Percentage.\n",
            "\n",
            "       Xid error events reported with Xid error code. The error  code  is  999\n",
            "       for unknown xid error.\n",
            "\n",
            "       Processor and Memory clock changes in MHz.\n",
            "\n",
            "       Violation due to Power capping with violation time in ns. (Tesla Only)\n",
            "\n",
            "       Violation  due  to  Thermal  capping with violation boolean flag (1/0).\n",
            "       (Tesla Only)\n",
            "\n",
            "       Notes:\n",
            "\n",
            "       Any statistic preceded by \"#\" is a comment.\n",
            "\n",
            "       Non supported device is displayed as \"#<device Index>, Device not  sup‐\n",
            "       ported\".\n",
            "\n",
            "       Non  supported  metric  is displayed as \"<device index>, <metric name>,\n",
            "       N/A, N/A\".\n",
            "\n",
            "       Violation due to Thermal/Power supported only for Tesla based products.\n",
            "       Thermal Violations are limited to Tesla K20 and higher.\n",
            "\n",
            "   D\bDe\bev\bvi\bic\bce\be M\bMo\bon\bni\bit\bto\bor\bri\bin\bng\bg\n",
            "       The  \"nvidia-smi dmon\" command-line is used to monitor one or more GPUs\n",
            "       (up to 4 devices) plugged into the system. This tool allows the user to\n",
            "       see  one line of monitoring data per monitoring cycle. The output is in\n",
            "       concise format and easy to interpret in interactive  mode.  The  output\n",
            "       data  per  line  is  limited  by  the terminal size. It is supported on\n",
            "       Tesla, GRID, Quadro and limited GeForce products for  Kepler  or  newer\n",
            "       GPUs  under  bare  metal 64 bits Linux. By default, the monitoring data\n",
            "       includes Power Usage, Temperature, SM clocks, Memory  clocks  and  Uti‐\n",
            "       lization  values  for  SM,  Memory, Encoder and Decoder. It can also be\n",
            "       configured to report other metrics such as frame buffer  memory  usage,\n",
            "       bar1 memory usage, power/thermal violations and aggregate single/double\n",
            "       bit ecc errors. If any of the metric is not supported on the device  or\n",
            "       any other error in fetching the metric is reported as \"-\" in the output\n",
            "       data. The user can also configure monitoring frequency and  the  number\n",
            "       of  monitoring  iterations  for  each  run.  There is also an option to\n",
            "       include date and time at each  line.  All  the  supported  options  are\n",
            "       exclusive and can be used together in any order.\n",
            "\n",
            "       U\bUs\bsa\bag\bge\be:\b:\n",
            "\n",
            "       1\b1)\b) D\bDe\bef\bfa\bau\bul\blt\bt w\bwi\bit\bth\bh n\bno\bo a\bar\brg\bgu\bum\bme\ben\bnt\bts\bs\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bd_\bm_\bo_\bn\n",
            "\n",
            "       Monitors  default  metrics  for up to 4 supported devices under natural\n",
            "       enumeration (starting with GPU index 0) at a frequency of 1  sec.  Runs\n",
            "       until terminated with ^C.\n",
            "\n",
            "       2\b2)\b) S\bSe\bel\ble\bec\bct\bt o\bon\bne\be o\bor\br m\bmo\bor\bre\be d\bde\bev\bvi\bic\bce\bes\bs\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bd_\bm_\bo_\bn _\b-_\bi _\b<_\bd_\be_\bv_\bi_\bc_\be_\b1_\b,_\bd_\be_\bv_\bi_\bc_\be_\b2_\b, _\b._\b. _\b, _\bd_\be_\bv_\bi_\bc_\be_\bN_\b>\n",
            "\n",
            "       Reports  default  metrics  for  the devices selected by comma separated\n",
            "       device list. The tool picks up to 4 supported  devices  from  the  list\n",
            "       under natural enumeration (starting with GPU index 0).\n",
            "\n",
            "       3\b3)\b) S\bSe\bel\ble\bec\bct\bt m\bme\bet\btr\bri\bic\bcs\bs t\bto\bo b\bbe\be d\bdi\bis\bsp\bpl\bla\bay\bye\bed\bd\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bd_\bm_\bo_\bn _\b-_\bs _\b<_\bm_\be_\bt_\br_\bi_\bc_\b__\bg_\br_\bo_\bu_\bp_\b>\n",
            "\n",
            "       <metric_group> can be one or more from the following:\n",
            "\n",
            "           p  -  Power  Usage  (in Watts) and Gpu/Memory Temperature (in C) if\n",
            "       supported\n",
            "\n",
            "           u - Utilization (SM, Memory, Encoder and Decoder Utilization in %)\n",
            "\n",
            "           c - Proc and Mem Clocks (in MHz)\n",
            "\n",
            "           v - Power Violations (in %) and Thermal Violations  (as  a  boolean\n",
            "       flag)\n",
            "\n",
            "           m - Frame Buffer and Bar1 memory usage (in MB)\n",
            "\n",
            "           e  -  ECC  (Number of aggregated single bit, double bit ecc errors)\n",
            "       and PCIe Replay errors\n",
            "\n",
            "           t - PCIe Rx and Tx Throughput in MB/s (Maxwell and above)\n",
            "\n",
            "       4\b4)\b) C\bCo\bon\bnf\bfi\big\bgu\bur\bre\be m\bmo\bon\bni\bit\bto\bor\bri\bin\bng\bg i\bit\bte\ber\bra\bat\bti\bio\bon\bns\bs\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bd_\bm_\bo_\bn _\b-_\bc _\b<_\bn_\bu_\bm_\bb_\be_\br _\bo_\bf _\bs_\ba_\bm_\bp_\bl_\be_\bs_\b>\n",
            "\n",
            "       Displays data for specified number of samples and exit.\n",
            "\n",
            "       5\b5)\b) C\bCo\bon\bnf\bfi\big\bgu\bur\bre\be m\bmo\bon\bni\bit\bto\bor\bri\bin\bng\bg f\bfr\bre\beq\bqu\bue\ben\bnc\bcy\by\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bd_\bm_\bo_\bn _\b-_\bd _\b<_\bt_\bi_\bm_\be _\bi_\bn _\bs_\be_\bc_\bs_\b>\n",
            "\n",
            "       Collects and displays data at every specified monitoring interval until\n",
            "       terminated with ^C.\n",
            "\n",
            "       6\b6)\b) D\bDi\bis\bsp\bpl\bla\bay\by d\bda\bat\bte\be\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bd_\bm_\bo_\bn _\b-_\bo _\bD\n",
            "\n",
            "       Prepends monitoring data with date in YYYYMMDD format.\n",
            "\n",
            "       7\b7)\b) D\bDi\bis\bsp\bpl\bla\bay\by t\bti\bim\bme\be\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bd_\bm_\bo_\bn _\b-_\bo _\bT\n",
            "\n",
            "       Prepends monitoring data with time in HH:MM:SS format.\n",
            "\n",
            "       8\b8)\b) H\bHe\bel\blp\bp I\bIn\bnf\bfo\bor\brm\bma\bat\bti\bio\bon\bn\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bd_\bm_\bo_\bn _\b-_\bh\n",
            "\n",
            "       Displays help information for using the command line.\n",
            "\n",
            "   D\bDa\bae\bem\bmo\bon\bn (\b(E\bEX\bXP\bPE\bER\bRI\bIM\bME\bEN\bNT\bTA\bAL\bL)\b)\n",
            "       The  \"nvidia-smi  daemon\" starts a background process to monitor one or\n",
            "       more GPUs plugged in to the system.  It  monitors  the  requested  GPUs\n",
            "       every  monitoring  cycle  and logs the file in compressed format at the\n",
            "       user provided path or the default location  at  /var/log/nvstats/.  The\n",
            "       log file is created with system's date appended to it and of the format\n",
            "       nvstats-YYYYMMDD. The flush operation to the log  file  is  done  every\n",
            "       alternate   monitoring   cycle.  Daemon  also  logs  it's  own  PID  at\n",
            "       /var/run/nvsmi.pid. By default, the monitoring data to persist includes\n",
            "       Power Usage, Temperature, SM clocks, Memory clocks and Utilization val‐\n",
            "       ues for SM, Memory, Encoder and Decoder. The daemon tools can  also  be\n",
            "       configured  to  record other metrics such as frame buffer memory usage,\n",
            "       bar1 memory usage, power/thermal violations and aggregate single/double\n",
            "       bit  ecc  errors.The default monitoring cycle is set to 10 secs and can\n",
            "       be configured via command-line. It is supported on Tesla, GRID,  Quadro\n",
            "       and  GeForce products for Kepler or newer GPUs under bare metal 64 bits\n",
            "       Linux. The daemon requires root privileges to run, and   only  supports\n",
            "       running  a  single instance on the system. All of the supported options\n",
            "       are exclusive and can be used together in any order.\n",
            "\n",
            "       U\bUs\bsa\bag\bge\be:\b:\n",
            "\n",
            "       1\b1)\b) D\bDe\bef\bfa\bau\bul\blt\bt w\bwi\bit\bth\bh n\bno\bo a\bar\brg\bgu\bum\bme\ben\bnt\bts\bs\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bd_\ba_\be_\bm_\bo_\bn\n",
            "\n",
            "       Runs in the background to monitor default metrics for up to 4 supported\n",
            "       devices under natural enumeration (starting with GPU index 0) at a fre‐\n",
            "       quency of 10 sec. The date stamped log file is created at /var/log/nvs‐\n",
            "       tats/.\n",
            "\n",
            "       2\b2)\b) S\bSe\bel\ble\bec\bct\bt o\bon\bne\be o\bor\br m\bmo\bor\bre\be d\bde\bev\bvi\bic\bce\bes\bs\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bd_\ba_\be_\bm_\bo_\bn _\b-_\bi _\b<_\bd_\be_\bv_\bi_\bc_\be_\b1_\b,_\bd_\be_\bv_\bi_\bc_\be_\b2_\b, _\b._\b. _\b, _\bd_\be_\bv_\bi_\bc_\be_\bN_\b>\n",
            "\n",
            "       Runs  in  the  background  to  monitor  default metrics for the devices\n",
            "       selected by comma separated device list. The tool picks up  to  4  sup‐\n",
            "       ported  devices  from the list under natural enumeration (starting with\n",
            "       GPU index 0).\n",
            "\n",
            "       3\b3)\b) S\bSe\bel\ble\bec\bct\bt m\bme\bet\btr\bri\bic\bcs\bs t\bto\bo b\bbe\be m\bmo\bon\bni\bit\bto\bor\bre\bed\bd\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bd_\ba_\be_\bm_\bo_\bn _\b-_\bs _\b<_\bm_\be_\bt_\br_\bi_\bc_\b__\bg_\br_\bo_\bu_\bp_\b>\n",
            "\n",
            "       <metric_group> can be one or more from the following:\n",
            "\n",
            "           p - Power Usage (in Watts) and Gpu/Memory  Temperature  (in  C)  if\n",
            "       supported\n",
            "\n",
            "           u - Utilization (SM, Memory, Encoder and Decoder Utilization in %)\n",
            "\n",
            "           c - Proc and Mem Clocks (in MHz)\n",
            "\n",
            "           v  -  Power  Violations (in %) and Thermal Violations (as a boolean\n",
            "       flag)\n",
            "\n",
            "           m - Frame Buffer and Bar1 memory usage (in MB)\n",
            "\n",
            "            e - ECC (Number of aggregated single bit, double bit  ecc  errors)\n",
            "       and PCIe Replay errors\n",
            "\n",
            "           t - PCIe Rx and Tx Throughput in MB/s (Maxwell and above)\n",
            "\n",
            "       4\b4)\b) C\bCo\bon\bnf\bfi\big\bgu\bur\bre\be m\bmo\bon\bni\bit\bto\bor\bri\bin\bng\bg f\bfr\bre\beq\bqu\bue\ben\bnc\bcy\by\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bd_\ba_\be_\bm_\bo_\bn _\b-_\bd _\b<_\bt_\bi_\bm_\be _\bi_\bn _\bs_\be_\bc_\bs_\b>\n",
            "\n",
            "       Collects data at every specified monitoring interval until terminated.\n",
            "\n",
            "       5\b5)\b) C\bCo\bon\bnf\bfi\big\bgu\bur\bre\be l\blo\bog\bg d\bdi\bir\bre\bec\bct\bto\bor\bry\by\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bd_\ba_\be_\bm_\bo_\bn _\b-_\bp _\b<_\bp_\ba_\bt_\bh _\bo_\bf _\bd_\bi_\br_\be_\bc_\bt_\bo_\br_\by_\b>\n",
            "\n",
            "       The log files are created at the specified directory.\n",
            "\n",
            "       6\b6)\b) C\bCo\bon\bnf\bfi\big\bgu\bur\bre\be l\blo\bog\bg f\bfi\bil\ble\be n\bna\bam\bme\be\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bd_\ba_\be_\bm_\bo_\bn _\b-_\bj _\b<_\bs_\bt_\br_\bi_\bn_\bg _\bt_\bo _\ba_\bp_\bp_\be_\bn_\bd _\bl_\bo_\bg _\bf_\bi_\bl_\be _\bn_\ba_\bm_\be_\b>\n",
            "\n",
            "       The command-line is used to append the log file name with the user pro‐\n",
            "       vided string.\n",
            "\n",
            "       7\b7)\b) T\bTe\ber\brm\bmi\bin\bna\bat\bte\be t\bth\bhe\be d\bda\bae\bem\bmo\bon\bn\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bd_\ba_\be_\bm_\bo_\bn _\b-_\bt\n",
            "\n",
            "       This command-line uses the stored PID (at /var/run/nvsmi.pid) to termi‐\n",
            "       nate the daemon. It makes the best effort to stop the daemon and offers\n",
            "       no guarantees for it's termination. In case the daemon  is  not  termi‐\n",
            "       nated,  then  the user can manually terminate by sending kill signal to\n",
            "       the daemon. Performing a GPU reset operation (via nvidia-smi)  requires\n",
            "       all  GPU  processes  to be exited, including the daemon. Users who have\n",
            "       the daemon open will see an error to the effect that the GPU is busy.\n",
            "\n",
            "       8\b8)\b) H\bHe\bel\blp\bp I\bIn\bnf\bfo\bor\brm\bma\bat\bti\bio\bon\bn\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bd_\ba_\be_\bm_\bo_\bn _\b-_\bh\n",
            "\n",
            "       Displays help information for using the command line.\n",
            "\n",
            "   R\bRe\bep\bpl\bla\bay\by M\bMo\bod\bde\be (\b(E\bEX\bXP\bPE\bER\bRI\bIM\bME\bEN\bNT\bTA\bAL\bL)\b)\n",
            "       The \"nvidia-smi replay\" command-line is used to extract/replay  all  or\n",
            "       parts  of  log file generated by the daemon. By default, the tool tries\n",
            "       to pull the metrics such as Power Usage, Temperature, SM clocks, Memory\n",
            "       clocks  and Utilization values for SM, Memory, Encoder and Decoder. The\n",
            "       replay tool can also fetch other metrics such as  frame  buffer  memory\n",
            "       usage,  bar1  memory usage, power/thermal violations and aggregate sin‐\n",
            "       gle/double bit ecc errors. There is an option to select a set  of  met‐\n",
            "       rics  to  replay,  If  any of the requested metric is not maintained or\n",
            "       logged as not-supported then it's shown as \"-\" in the output. The  for‐\n",
            "       mat  of data produced by this mode is such that the user is running the\n",
            "       device monitoring utility  interactively.  The  command  line  requires\n",
            "       mandatory option \"-f\" to specify complete path of the log filename, all\n",
            "       the other supported options are exclusive and can be used  together  in\n",
            "       any order.\n",
            "\n",
            "       U\bUs\bsa\bag\bge\be:\b:\n",
            "\n",
            "       1\b1)\b) S\bSp\bpe\bec\bci\bif\bfy\by l\blo\bog\bg f\bfi\bil\ble\be t\bto\bo b\bbe\be r\bre\bep\bpl\bla\bay\bye\bed\bd\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\br_\be_\bp_\bl_\ba_\by _\b-_\bf _\b<_\bl_\bo_\bg _\bf_\bi_\bl_\be _\bn_\ba_\bm_\be_\b>\n",
            "\n",
            "       Fetches  monitoring  data  from  the compressed log file and allows the\n",
            "       user to see one line of monitoring data  (default  metrics  with  time-\n",
            "       stamp) for each monitoring iteration stored in the log file. A new line\n",
            "       of monitoring data is replayed every other second irrespective  of  the\n",
            "       actual monitoring frequency maintained at the time of collection. It is\n",
            "       displayed till the end of file or until terminated by ^C.\n",
            "\n",
            "       2\b2)\b) F\bFi\bil\blt\bte\ber\br m\bme\bet\btr\bri\bic\bcs\bs t\bto\bo b\bbe\be r\bre\bep\bpl\bla\bay\bye\bed\bd\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\br_\be_\bp_\bl_\ba_\by _\b-_\bf _\b<_\bp_\ba_\bt_\bh _\bt_\bo _\bl_\bo_\bg _\bf_\bi_\bl_\be_\b> _\b-_\bs _\b<_\bm_\be_\bt_\br_\bi_\bc_\b__\bg_\br_\bo_\bu_\bp_\b>\n",
            "\n",
            "       <metric_group> can be one or more from the following:\n",
            "\n",
            "           p - Power Usage (in Watts) and Gpu/Memory  Temperature  (in  C)  if\n",
            "       supported\n",
            "\n",
            "           u - Utilization (SM, Memory, Encoder and Decoder Utilization in %)\n",
            "\n",
            "           c - Proc and Mem Clocks (in MHz)\n",
            "\n",
            "           v  -  Power  Violations (in %) and Thermal Violations (as a boolean\n",
            "       flag)\n",
            "\n",
            "           m - Frame Buffer and Bar1 memory usage (in MB)\n",
            "\n",
            "            e - ECC (Number of aggregated single bit, double bit  ecc  errors)\n",
            "       and PCIe Replay errors\n",
            "\n",
            "           t - PCIe Rx and Tx Throughput in MB/s (Maxwell and above)\n",
            "\n",
            "       3\b3)\b) L\bLi\bim\bmi\bit\bt r\bre\bep\bpl\bla\bay\by t\bto\bo o\bon\bne\be o\bor\br m\bmo\bor\bre\be d\bde\bev\bvi\bic\bce\bes\bs\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\br_\be_\bp_\bl_\ba_\by _\b-_\bf _\b<_\bl_\bo_\bg _\bf_\bi_\bl_\be_\b> _\b-_\bi _\b<_\bd_\be_\bv_\bi_\bc_\be_\b1_\b,_\bd_\be_\bv_\bi_\bc_\be_\b2_\b, _\b._\b. _\b, _\bd_\be_\bv_\bi_\bc_\be_\bN_\b>\n",
            "\n",
            "       Limits reporting of the metrics to the set of devices selected by comma\n",
            "       separated device list. The tool skips any of the devices not maintained\n",
            "       in the log file.\n",
            "\n",
            "       4\b4)\b) R\bRe\bes\bst\btr\bri\bic\bct\bt t\bth\bhe\be t\bti\bim\bme\be f\bfr\bra\bam\bme\be b\bbe\bet\btw\bwe\bee\ben\bn w\bwh\bhi\bic\bch\bh d\bda\bat\bta\ba i\bis\bs r\bre\bep\bpo\bor\brt\bte\bed\bd\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi  _\br_\be_\bp_\bl_\ba_\by  _\b-_\bf _\b<_\bl_\bo_\bg _\bf_\bi_\bl_\be_\b> _\b-_\bb _\b<_\bs_\bt_\ba_\br_\bt _\bt_\bi_\bm_\be _\bi_\bn _\bH_\bH_\b:_\bM_\bM_\b:_\bS_\bS _\bf_\bo_\br_\bm_\ba_\bt_\b> _\b-_\be\n",
            "       _\b<_\be_\bn_\bd _\bt_\bi_\bm_\be _\bi_\bn _\bH_\bH_\b:_\bM_\bM_\b:_\bS_\bS _\bf_\bo_\br_\bm_\ba_\bt_\b>\n",
            "\n",
            "       This option allows the data to be limited between  the  specified  time\n",
            "       range.  Specifying  time as 0 with -b or -e option implies start or end\n",
            "       file respectively.\n",
            "\n",
            "       5\b5)\b) R\bRe\bed\bdi\bir\bre\bec\bct\bt r\bre\bep\bpl\bla\bay\by i\bin\bnf\bfo\bor\brm\bma\bat\bti\bio\bon\bn t\bto\bo a\ba l\blo\bog\bg f\bfi\bil\ble\be\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\br_\be_\bp_\bl_\ba_\by _\b-_\bf _\b<_\bl_\bo_\bg _\bf_\bi_\bl_\be_\b> _\b-_\br _\b<_\bo_\bu_\bt_\bp_\bu_\bt _\bf_\bi_\bl_\be _\bn_\ba_\bm_\be_\b>\n",
            "\n",
            "       This option takes log file as an input  and  extracts  the  information\n",
            "       related to default metrics in the specified output file.\n",
            "\n",
            "       6\b6)\b) H\bHe\bel\blp\bp I\bIn\bnf\bfo\bor\brm\bma\bat\bti\bio\bon\bn\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\br_\be_\bp_\bl_\ba_\by _\b-_\bh\n",
            "\n",
            "       Displays help information for using the command line.\n",
            "\n",
            "   P\bPr\bro\boc\bce\bes\bss\bs M\bMo\bon\bni\bit\bto\bor\bri\bin\bng\bg\n",
            "       The  \"nvidia-smi  pmon\"  command-line  is  used  to monitor compute and\n",
            "       graphics processes running on one  or  more  GPUs  (up  to  4  devices)\n",
            "       plugged  into  the system. This tool allows the user to see the statis‐\n",
            "       tics for all the running processes on each device at  every  monitoring\n",
            "       cycle.  The output is in concise format and easy to interpret in inter‐\n",
            "       active mode. The output data per line is limited by the terminal  size.\n",
            "       It is supported on Tesla, GRID, Quadro and limited GeForce products for\n",
            "       Kepler or newer GPUs under bare metal 64 bits Linux.  By  default,  the\n",
            "       monitoring  data  for  each  process includes the pid, command name and\n",
            "       average utilization values for SM, Memory, Encoder  and  Decoder  since\n",
            "       the  last  monitoring  cycle. It can also be configured to report frame\n",
            "       buffer memory usage for each process. If there is  no  process  running\n",
            "       for  the  device,  then  all  the  metrics  are reported as \"-\" for the\n",
            "       device. If any of the metric is not supported  on  the  device  or  any\n",
            "       other  error in fetching the metric is also reported as \"-\" in the out‐\n",
            "       put data. The user can also configure monitoring frequency and the num‐\n",
            "       ber  of  monitoring iterations for each run. There is also an option to\n",
            "       include date and time at each  line.  All  the  supported  options  are\n",
            "       exclusive and can be used together in any order.\n",
            "\n",
            "       U\bUs\bsa\bag\bge\be:\b:\n",
            "\n",
            "       1\b1)\b) D\bDe\bef\bfa\bau\bul\blt\bt w\bwi\bit\bth\bh n\bno\bo a\bar\brg\bgu\bum\bme\ben\bnt\bts\bs\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bp_\bm_\bo_\bn\n",
            "\n",
            "       Monitors all the processes running on each device for up to 4 supported\n",
            "       devices under natural enumeration (starting with GPU index 0) at a fre‐\n",
            "       quency of 1 sec. Runs until terminated with ^C.\n",
            "\n",
            "       2\b2)\b) S\bSe\bel\ble\bec\bct\bt o\bon\bne\be o\bor\br m\bmo\bor\bre\be d\bde\bev\bvi\bic\bce\bes\bs\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bp_\bm_\bo_\bn _\b-_\bi _\b<_\bd_\be_\bv_\bi_\bc_\be_\b1_\b,_\bd_\be_\bv_\bi_\bc_\be_\b2_\b, _\b._\b. _\b, _\bd_\be_\bv_\bi_\bc_\be_\bN_\b>\n",
            "\n",
            "       Reports  statistics  for  all  the  processes  running  on  the devices\n",
            "       selected by comma separated device list. The tool picks up  to  4  sup‐\n",
            "       ported  devices  from the list under natural enumeration (starting with\n",
            "       GPU index 0).\n",
            "\n",
            "       3\b3)\b) S\bSe\bel\ble\bec\bct\bt m\bme\bet\btr\bri\bic\bcs\bs t\bto\bo b\bbe\be d\bdi\bis\bsp\bpl\bla\bay\bye\bed\bd\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bp_\bm_\bo_\bn _\b-_\bs _\b<_\bm_\be_\bt_\br_\bi_\bc_\b__\bg_\br_\bo_\bu_\bp_\b>\n",
            "\n",
            "       <metric_group> can be one or more from the following:\n",
            "\n",
            "           u - Utilization (SM, Memory, Encoder and  Decoder  Utilization  for\n",
            "       the  process  in  %). Reports average utilization since last monitoring\n",
            "       cycle.\n",
            "\n",
            "           m - Frame Buffer usage (in MB).  Reports  instantaneous  value  for\n",
            "       memory usage.\n",
            "\n",
            "       4\b4)\b) C\bCo\bon\bnf\bfi\big\bgu\bur\bre\be m\bmo\bon\bni\bit\bto\bor\bri\bin\bng\bg i\bit\bte\ber\bra\bat\bti\bio\bon\bns\bs\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bp_\bm_\bo_\bn _\b-_\bc _\b<_\bn_\bu_\bm_\bb_\be_\br _\bo_\bf _\bs_\ba_\bm_\bp_\bl_\be_\bs_\b>\n",
            "\n",
            "       Displays data for specified number of samples and exit.\n",
            "\n",
            "       5\b5)\b) C\bCo\bon\bnf\bfi\big\bgu\bur\bre\be m\bmo\bon\bni\bit\bto\bor\bri\bin\bng\bg f\bfr\bre\beq\bqu\bue\ben\bnc\bcy\by\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bp_\bm_\bo_\bn _\b-_\bd _\b<_\bt_\bi_\bm_\be _\bi_\bn _\bs_\be_\bc_\bs_\b>\n",
            "\n",
            "       Collects and displays data at every specified monitoring interval until\n",
            "       terminated with ^C. The monitoring frequency must be between  1  to  10\n",
            "       secs.\n",
            "\n",
            "       6\b6)\b) D\bDi\bis\bsp\bpl\bla\bay\by d\bda\bat\bte\be\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bp_\bm_\bo_\bn _\b-_\bo _\bD\n",
            "\n",
            "       Prepends monitoring data with date in YYYYMMDD format.\n",
            "\n",
            "       7\b7)\b) D\bDi\bis\bsp\bpl\bla\bay\by t\bti\bim\bme\be\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bp_\bm_\bo_\bn _\b-_\bo _\bT\n",
            "\n",
            "       Prepends monitoring data with time in HH:MM:SS format.\n",
            "\n",
            "       8\b8)\b) H\bHe\bel\blp\bp I\bIn\bnf\bfo\bor\brm\bma\bat\bti\bio\bon\bn\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bp_\bm_\bo_\bn _\b-_\bh\n",
            "\n",
            "       Displays help information for using the command line.\n",
            "\n",
            "   T\bTo\bop\bpo\bol\blo\bog\bgy\by (\b(E\bEX\bXP\bPE\bER\bRI\bIM\bME\bEN\bNT\bTA\bAL\bL)\b)\n",
            "       List  topology information about the system's GPUs, how they connect to\n",
            "       each other as well as qualified NICs capable of RDMA\n",
            "\n",
            "       Displays a matrix of available GPUs with the following legend:\n",
            "\n",
            "       Legend:\n",
            "\n",
            "                        X    = Self\n",
            "                        SYS  = Connection traversing PCIe as well as  the  SMP\n",
            "                      interconnect between NUMA nodes (e.g., QPI/UPI)\n",
            "                        NODE  =  Connection  traversing  PCIe  as  well as the\n",
            "                      interconnect between PCIe Host  Bridges  within  a  NUMA\n",
            "                      node\n",
            "                        PHB   =  Connection  traversing PCIe as well as a PCIe\n",
            "                      Host Bridge (typically the CPU)\n",
            "                        PXB  = Connection traversing  multiple  PCIe  switches\n",
            "                      (without traversing the PCIe Host Bridge)\n",
            "                        PIX  = Connection traversing a single PCIe switch\n",
            "                        NV#  = Connection traversing a bonded set of # NVLinks\n",
            "\n",
            "   v\bvG\bGP\bPU\bU M\bMa\ban\bna\bag\bge\bem\bme\ben\bnt\bt\n",
            "       The  \"nvidia-smi  vgpu\" command reports on GRID vGPUs executing on sup‐\n",
            "       ported GPUs and hypervisors (refer to driver  release  notes  for  sup‐\n",
            "       ported  platforms).  Summary reporting provides basic information about\n",
            "       vGPUs currently executing on the  system.  Additional  options  provide\n",
            "       detailed  reporting  of vGPU properties, per-vGPU reporting of SM, Mem‐\n",
            "       ory, Encoder, and Decoder utilization, and per-GPU  reporting  of  sup‐\n",
            "       ported  and creatable vGPUs. Periodic reports can be automatically gen‐\n",
            "       erated by specifying a configurable loop frequency to any command.\n",
            "\n",
            "       U\bUs\bsa\bag\bge\be:\b:\n",
            "\n",
            "       1\b1)\b) H\bHe\bel\blp\bp I\bIn\bnf\bfo\bor\brm\bma\bat\bti\bio\bon\bn\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bv_\bg_\bp_\bu _\b-_\bh\n",
            "\n",
            "       Displays help information for using the command line.\n",
            "\n",
            "       2\b2)\b) D\bDe\bef\bfa\bau\bul\blt\bt w\bwi\bit\bth\bh n\bno\bo a\bar\brg\bgu\bum\bme\ben\bnt\bts\bs\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bv_\bg_\bp_\bu\n",
            "\n",
            "       Reports summary of all the vGPUs currently active on each device.\n",
            "\n",
            "       3\b3)\b) D\bDi\bis\bsp\bpl\bla\bay\by d\bde\bet\bta\bai\bil\ble\bed\bd i\bin\bnf\bfo\bo o\bon\bn c\bcu\bur\brr\bre\ben\bnt\btl\bly\by a\bac\bct\bti\biv\bve\be v\bvG\bGP\bPU\bUs\bs\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bv_\bg_\bp_\bu _\b-_\bq\n",
            "\n",
            "       Collects and displays information on currently  active  vGPUs  on  each\n",
            "       device, including driver version, utilization, and other information.\n",
            "\n",
            "       4\b4)\b) S\bSe\bel\ble\bec\bct\bt o\bon\bne\be o\bor\br m\bmo\bor\bre\be d\bde\bev\bvi\bic\bce\bes\bs\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bv_\bg_\bp_\bu _\b-_\bi _\b<_\bd_\be_\bv_\bi_\bc_\be_\b1_\b,_\bd_\be_\bv_\bi_\bc_\be_\b2_\b, _\b._\b. _\b, _\bd_\be_\bv_\bi_\bc_\be_\bN_\b>\n",
            "\n",
            "       Reports  summary  for  all  the  vGPUs  currently active on the devices\n",
            "       selected by comma-separated device list.\n",
            "\n",
            "       5\b5)\b) D\bDi\bis\bsp\bpl\bla\bay\by s\bsu\bup\bpp\bpo\bor\brt\bte\bed\bd v\bvG\bGP\bPU\bUs\bs\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bv_\bg_\bp_\bu _\b-_\bs\n",
            "\n",
            "       Displays vGPU types supported on each device. Use the  -v  /  --verbose\n",
            "       option to show detailed info on each vGPU type.\n",
            "\n",
            "       6\b6)\b) D\bDi\bis\bsp\bpl\bla\bay\by c\bcr\bre\bea\bat\bta\bab\bbl\ble\be v\bvG\bGP\bPU\bUs\bs\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bv_\bg_\bp_\bu _\b-_\bc\n",
            "\n",
            "       Displays  vGPU types creatable on each device. This varies dynamically,\n",
            "       depending on the vGPUs already active on  the  device.  Use  the  -v  /\n",
            "       --verbose option to show detailed info on each vGPU type.\n",
            "\n",
            "       7\b7)\b) R\bRe\bep\bpo\bor\brt\bt u\but\bti\bil\bli\biz\bza\bat\bti\bio\bon\bn f\bfo\bor\br c\bcu\bur\brr\bre\ben\bnt\btl\bly\by a\bac\bct\bti\biv\bve\be v\bvG\bGP\bPU\bUs\bs.\b.\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bv_\bg_\bp_\bu _\b-_\bu\n",
            "\n",
            "       Reports  average utilization (SM, Memory, Encoder and Decoder) for each\n",
            "       active vGPU since last monitoring cycle. The default cycle  time  is  1\n",
            "       second,  and the command runs until terminated with ^C. If a device has\n",
            "       no active vGPUs, its metrics are reported as \"-\".\n",
            "\n",
            "       8\b8)\b) C\bCo\bon\bnf\bfi\big\bgu\bur\bre\be l\blo\boo\bop\bp f\bfr\bre\beq\bqu\bue\ben\bnc\bcy\by\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bv_\bg_\bp_\bu _\b[_\b-_\bs _\b-_\bc _\b-_\bq _\b-_\bu_\b] _\b-_\bl _\b<_\bt_\bi_\bm_\be _\bi_\bn _\bs_\be_\bc_\bs_\b>\n",
            "\n",
            "       Collects and displays data at a specified loop  interval  until  termi‐\n",
            "       nated  with  ^C. The loop frequency must be between 1 and 10 secs. When\n",
            "       no time is specified, the loop frequency defaults to 5 secs.\n",
            "\n",
            "       9\b9)\b) D\bDi\bis\bsp\bpl\bla\bay\by G\bGP\bPU\bU e\ben\bng\bgi\bin\bne\be u\bus\bsa\bag\bge\be\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bv_\bg_\bp_\bu _\b-_\bp\n",
            "\n",
            "       Display GPU engine usage of currently active processes running  in  the\n",
            "       vGPU VMs.\n",
            "\n",
            "       1\b10\b0)\b) D\bDi\bis\bsp\bpl\bla\bay\by m\bmi\big\bgr\bra\bat\bti\bio\bon\bn c\bca\bap\bpa\bab\bbi\bit\btl\bli\bit\bti\bie\bes\bs.\b.\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bv_\bg_\bp_\bu _\b-_\bm\n",
            "\n",
            "       Display pGPU's migration/suspend/resume capability.\n",
            "\n",
            "       1\b11\b1)\b) D\bDi\bis\bsp\bpl\bla\bay\by N\bNv\bvi\bid\bdi\bia\ba E\bEn\bnc\bco\bod\bde\ber\br s\bse\bes\bss\bsi\bio\bon\bn i\bin\bnf\bfo\bo.\b.\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bv_\bg_\bp_\bu _\b-_\be_\bs\n",
            "\n",
            "       Display  the  information  about encoder sessions for currently running\n",
            "       vGPUs.\n",
            "\n",
            "       1\b12\b2)\b) D\bDi\bis\bsp\bpl\bla\bay\by a\bac\bcc\bco\bou\bun\bnt\bti\bin\bng\bg s\bst\bta\bat\bti\bis\bst\bti\bic\bcs\bs.\b.\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bv_\bg_\bp_\bu _\b-_\b-_\bq_\bu_\be_\br_\by_\b-_\ba_\bc_\bc_\bo_\bu_\bn_\bt_\be_\bd_\b-_\ba_\bp_\bp_\bs_\b=_\b[_\bi_\bn_\bp_\bu_\bt _\bp_\ba_\br_\ba_\bm_\be_\bt_\be_\br_\bs_\b]\n",
            "\n",
            "       Display accounting stats for compute/graphics processes.\n",
            "\n",
            "       To find list of properties which can  be  queried,  run  -  'nvidia-smi\n",
            "       --help-query-accounted-apps'.\n",
            "\n",
            "       1\b13\b3)\b) D\bDi\bis\bsp\bpl\bla\bay\by N\bNv\bvi\bid\bdi\bia\ba F\bFr\bra\bam\bme\be B\bBu\buf\bff\bfe\ber\br C\bCa\bap\bpt\btu\bur\bre\be s\bse\bes\bss\bsi\bio\bon\bn i\bin\bnf\bfo\bo.\b.\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bv_\bg_\bp_\bu _\b-_\bf_\bs\n",
            "\n",
            "       Display the information about FBC sessions for currently running vGPUs.\n",
            "\n",
            "       _\bN_\bo_\bt_\be  _\b:  _\bH_\bo_\br_\bi_\bz_\bo_\bn_\bt_\ba_\bl  _\br_\be_\bs_\bo_\bl_\bu_\bt_\bi_\bo_\bn_\b,  _\bv_\be_\br_\bt_\bi_\bc_\ba_\bl  _\br_\be_\bs_\bo_\bl_\bu_\bt_\bi_\bo_\bn_\b, _\ba_\bv_\be_\br_\ba_\bg_\be _\bF_\bP_\bS _\ba_\bn_\bd\n",
            "       _\ba_\bv_\be_\br_\ba_\bg_\be _\bl_\ba_\bt_\be_\bn_\bc_\by _\bd_\ba_\bt_\ba _\bf_\bo_\br _\ba _\bF_\bB_\bC _\bs_\be_\bs_\bs_\bi_\bo_\bn _\bm_\ba_\by _\bb_\be _\bz_\be_\br_\bo _\bi_\bf _\bt_\bh_\be_\br_\be _\ba_\br_\be _\bn_\bo  _\bn_\be_\bw\n",
            "       _\bf_\br_\ba_\bm_\be_\bs _\bc_\ba_\bp_\bt_\bu_\br_\be_\bd _\bs_\bi_\bn_\bc_\be _\bt_\bh_\be _\bs_\be_\bs_\bs_\bi_\bo_\bn _\bs_\bt_\ba_\br_\bt_\be_\bd_\b.\n",
            "\n",
            "   M\bMI\bIG\bG M\bMa\ban\bna\bag\bge\bem\bme\ben\bnt\bt\n",
            "       The  privileged  \"nvidia-smi  mig\"  command-line is used to manage MIG-\n",
            "       enabled GPUs. It provides options  to  create,  list  and  destroy  GPU\n",
            "       instances and compute instances.\n",
            "\n",
            "       U\bUs\bsa\bag\bge\be:\b:\n",
            "\n",
            "       1\b1)\b) D\bDi\bis\bsp\bpl\bla\bay\by h\bhe\bel\blp\bp m\bme\ben\bnu\bu\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bm_\bi_\bg _\b-_\bh\n",
            "\n",
            "       Displays help menu for using the command-line.\n",
            "\n",
            "       2\b2)\b) S\bSe\bel\ble\bec\bct\bt o\bon\bne\be o\bor\br m\bmo\bor\bre\be G\bGP\bPU\bUs\bs\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bm_\bi_\bg _\b-_\bi _\b<_\bG_\bP_\bU _\bI_\bD_\bs_\b>\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bm_\bi_\bg _\b-_\b-_\bi_\bd _\b<_\bG_\bP_\bU _\bI_\bD_\bs_\b>\n",
            "\n",
            "       Selects  one  or more GPUs using the given comma-separated GPU indexes,\n",
            "       PCI bus IDs or UUIDs.  If  not  used,  the  given  command-line  option\n",
            "       applies to all of the supported GPUs.\n",
            "\n",
            "       3\b3)\b) S\bSe\bel\ble\bec\bct\bt o\bon\bne\be o\bor\br m\bmo\bor\bre\be G\bGP\bPU\bU i\bin\bns\bst\bta\ban\bnc\bce\bes\bs\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bm_\bi_\bg _\b-_\bg_\bi _\b<_\bG_\bP_\bU _\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be _\bI_\bD_\bs_\b>\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bm_\bi_\bg _\b-_\b-_\bg_\bp_\bu_\b-_\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be_\b-_\bi_\bd _\b<_\bG_\bP_\bU _\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be _\bI_\bD_\bs_\b>\n",
            "\n",
            "       Selects  one  or more GPU instances using the given comma-separated GPU\n",
            "       instance IDs. If not used, the given command-line option applies to all\n",
            "       of the GPU instances.\n",
            "\n",
            "       4\b4)\b) S\bSe\bel\ble\bec\bct\bt o\bon\bne\be o\bor\br m\bmo\bor\bre\be c\bco\bom\bmp\bpu\but\bte\be i\bin\bns\bst\bta\ban\bnc\bce\bes\bs\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bm_\bi_\bg _\b-_\bc_\bi _\b<_\bc_\bo_\bm_\bp_\bu_\bt_\be _\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be _\bI_\bD_\bs_\b>\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bm_\bi_\bg _\b-_\b-_\bc_\bo_\bm_\bp_\bu_\bt_\be_\b-_\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be_\b-_\bi_\bd _\b<_\bc_\bo_\bm_\bp_\bu_\bt_\be _\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be _\bI_\bD_\bs_\b>\n",
            "\n",
            "       Selects  one  or more compute instances using the given comma-separated\n",
            "       compute instance IDs.  If  not  used,  the  given  command-line  option\n",
            "       applies to all of the compute instances.\n",
            "\n",
            "       5\b5)\b) L\bLi\bis\bst\bt G\bGP\bPU\bU i\bin\bns\bst\bta\ban\bnc\bce\be p\bpr\bro\bof\bfi\bil\ble\bes\bs\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bm_\bi_\bg _\b-_\bl_\bg_\bi_\bp _\b-_\bi _\b<_\bG_\bP_\bU _\bI_\bD_\bs_\b>\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bm_\bi_\bg _\b-_\b-_\bl_\bi_\bs_\bt_\b-_\bg_\bp_\bu_\b-_\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be_\b-_\bp_\br_\bo_\bf_\bi_\bl_\be_\bs _\b-_\b-_\bi_\bd _\b<_\bG_\bP_\bU _\bI_\bD_\bs_\b>\n",
            "\n",
            "       Lists  GPU  instance  profiles,  their  availability  and IDs. Profiles\n",
            "       describe the supported types of GPU instances, including all of the GPU\n",
            "       resources they exclusively control.\n",
            "\n",
            "       6\b6)\b) L\bLi\bis\bst\bt G\bGP\bPU\bU i\bin\bns\bst\bta\ban\bnc\bce\be p\bpo\bos\bss\bsi\bib\bbl\ble\be p\bpl\bla\bac\bce\bem\bme\ben\bnt\bts\bs\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bm_\bi_\bg _\b-_\bl_\bg_\bi_\bp_\bp _\b-_\bi _\b<_\bG_\bP_\bU _\bI_\bD_\bs_\b>\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bm_\bi_\bg _\b-_\b-_\bl_\bi_\bs_\bt_\b-_\bg_\bp_\bu_\b-_\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be_\b-_\bp_\bo_\bs_\bs_\bi_\bb_\bl_\be_\b-_\bp_\bl_\ba_\bc_\be_\bm_\be_\bn_\bt_\bs _\b-_\b-_\bi_\bd _\b<_\bG_\bP_\bU _\bI_\bD_\bs_\b>\n",
            "\n",
            "       Lists  GPU  instance  possible placements. Possible placements describe\n",
            "       the locations of the supported types of GPU instances within the GPU.\n",
            "\n",
            "       7\b7)\b) C\bCr\bre\bea\bat\bte\be G\bGP\bPU\bU i\bin\bns\bst\bta\ban\bnc\bce\be\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bm_\bi_\bg _\b-_\bc_\bg_\bi _\b<_\bG_\bP_\bU _\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be _\bs_\bp_\be_\bc_\bi_\bf_\bi_\be_\br_\bs_\b> _\b-_\bi _\b<_\bG_\bP_\bU _\bI_\bD_\bs_\b>\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bm_\bi_\bg _\b-_\b-_\bc_\br_\be_\ba_\bt_\be_\b-_\bg_\bp_\bu_\b-_\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be  _\b<_\bG_\bP_\bU  _\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be  _\bs_\bp_\be_\bc_\bi_\bf_\bi_\be_\br_\bs_\b>  _\b-_\b-_\bi_\bd\n",
            "       _\b<_\bG_\bP_\bU _\bI_\bD_\bs_\b>\n",
            "\n",
            "       Creates  GPU  instances  for  the  given GPU instance specifiers. A GPU\n",
            "       instance specifier comprises a GPU instance profile name or ID  and  an\n",
            "       optional  placement  specifier  consisting  of  a colon and a placement\n",
            "       start index. The command fails if the GPU resources required  to  allo‐\n",
            "       cate the requested GPU instances are not available, or if the placement\n",
            "       index is not valid for the given profile.\n",
            "\n",
            "       8\b8)\b) C\bCr\bre\bea\bat\bte\be a\ba G\bGP\bPU\bU i\bin\bns\bst\bta\ban\bnc\bce\be a\bal\blo\bon\bng\bg w\bwi\bit\bth\bh t\bth\bhe\be d\bde\bef\bfa\bau\bul\blt\bt c\bco\bom\bmp\bpu\but\bte\be i\bin\bns\bst\bta\ban\bnc\bce\be\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bm_\bi_\bg _\b-_\bc_\bg_\bi _\b<_\bG_\bP_\bU _\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be _\bp_\br_\bo_\bf_\bi_\bl_\be _\bI_\bD_\bs _\bo_\br _\bn_\ba_\bm_\be_\bs_\b> _\b-_\bi _\b<_\bG_\bP_\bU _\bI_\bD_\bs_\b> _\b-_\bC\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bm_\bi_\bg  _\b-_\b-_\bc_\br_\be_\ba_\bt_\be_\b-_\bg_\bp_\bu_\b-_\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be  _\b<_\bG_\bP_\bU  _\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be  _\bp_\br_\bo_\bf_\bi_\bl_\be  _\bI_\bD_\bs  _\bo_\br\n",
            "       _\bn_\ba_\bm_\be_\bs_\b> _\b-_\b-_\bi_\bd _\b<_\bG_\bP_\bU _\bI_\bD_\bs_\b> _\b-_\b-_\bd_\be_\bf_\ba_\bu_\bl_\bt_\b-_\bc_\bo_\bm_\bp_\bu_\bt_\be_\b-_\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be\n",
            "\n",
            "       9\b9)\b) L\bLi\bis\bst\bt G\bGP\bPU\bU i\bin\bns\bst\bta\ban\bnc\bce\bes\bs\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bm_\bi_\bg _\b-_\bl_\bg_\bi _\b-_\bi _\b<_\bG_\bP_\bU _\bI_\bD_\bs_\b>\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bm_\bi_\bg _\b-_\b-_\bl_\bi_\bs_\bt_\b-_\bg_\bp_\bu_\b-_\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be_\bs _\b-_\b-_\bi_\bd _\b<_\bG_\bP_\bU _\bI_\bD_\bs_\b>\n",
            "\n",
            "       Lists GPU instances and their IDs.\n",
            "\n",
            "       1\b10\b0)\b) D\bDe\bes\bst\btr\bro\boy\by G\bGP\bPU\bU i\bin\bns\bst\bta\ban\bnc\bce\be\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bm_\bi_\bg _\b-_\bd_\bg_\bi _\b-_\bg_\bi _\b<_\bG_\bP_\bU _\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be _\bI_\bD_\bs_\b> _\b-_\bi _\b<_\bG_\bP_\bU _\bI_\bD_\bs_\b>\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi  _\bm_\bi_\bg _\b-_\b-_\bd_\be_\bs_\bt_\br_\bo_\by_\b-_\bg_\bp_\bu_\b-_\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be_\bs _\b-_\b-_\bg_\bp_\bu_\b-_\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be_\b-_\bi_\bd _\b<_\bG_\bP_\bU _\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be\n",
            "       _\bI_\bD_\bs_\b> _\b-_\b-_\bi_\bd _\b<_\bG_\bP_\bU _\bI_\bD_\bs_\b>\n",
            "\n",
            "       Destroys GPU instances. The command fails if the requested GPU instance\n",
            "       is in use by an application.\n",
            "\n",
            "       1\b11\b1)\b) L\bLi\bis\bst\bt c\bco\bom\bmp\bpu\but\bte\be i\bin\bns\bst\bta\ban\bnc\bce\be p\bpr\bro\bof\bfi\bil\ble\bes\bs\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bm_\bi_\bg _\b-_\bl_\bc_\bi_\bp _\b-_\bg_\bi _\b<_\bG_\bP_\bU _\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be _\bI_\bD_\bs_\b> _\b-_\bi _\b<_\bG_\bP_\bU _\bI_\bD_\bs_\b>\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi  _\bm_\bi_\bg _\b-_\b-_\bl_\bi_\bs_\bt_\b-_\bc_\bo_\bm_\bp_\bu_\bt_\be_\b-_\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be_\b-_\bp_\br_\bo_\bf_\bi_\bl_\be_\bs _\b-_\b-_\bg_\bp_\bu_\b-_\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be_\b-_\bi_\bd _\b<_\bG_\bP_\bU\n",
            "       _\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be _\bI_\bD_\bs_\b> _\b-_\b-_\bi_\bd _\b<_\bG_\bP_\bU _\bI_\bD_\bs_\b>\n",
            "\n",
            "       Lists compute instance profiles, their availability and  IDs.  Profiles\n",
            "       describe the supported types of compute instances, including all of the\n",
            "       GPU resources they share or exclusively control.\n",
            "\n",
            "       1\b12\b2)\b) C\bCr\bre\bea\bat\bte\be c\bco\bom\bmp\bpu\but\bte\be i\bin\bns\bst\bta\ban\bnc\bce\be\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bm_\bi_\bg _\b-_\bc_\bc_\bi _\b<_\bc_\bo_\bm_\bp_\bu_\bt_\be _\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be _\bp_\br_\bo_\bf_\bi_\bl_\be _\bI_\bD_\bs _\bo_\br  _\bn_\ba_\bm_\be_\bs_\b>  _\b-_\bg_\bi  _\b<_\bG_\bP_\bU\n",
            "       _\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be _\bI_\bD_\bs_\b> _\b-_\bi _\b<_\bG_\bP_\bU _\bI_\bD_\bs_\b>\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi  _\bm_\bi_\bg _\b-_\b-_\bc_\br_\be_\ba_\bt_\be_\b-_\bc_\bo_\bm_\bp_\bu_\bt_\be_\b-_\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be _\b<_\bc_\bo_\bm_\bp_\bu_\bt_\be _\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be _\bp_\br_\bo_\bf_\bi_\bl_\be _\bI_\bD_\bs\n",
            "       _\bo_\br _\bn_\ba_\bm_\be_\bs_\b> _\b-_\b-_\bg_\bp_\bu_\b-_\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be_\b-_\bi_\bd _\b<_\bG_\bP_\bU _\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be _\bI_\bD_\bs_\b> _\b-_\b-_\bi_\bd _\b<_\bG_\bP_\bU _\bI_\bD_\bs_\b>\n",
            "\n",
            "       Creates compute instances for the given compute instance profile IDs or\n",
            "       names.  The command fails if the GPU resources required to allocate the\n",
            "       requested compute instances are not available.\n",
            "\n",
            "       1\b13\b3)\b) L\bLi\bis\bst\bt c\bco\bom\bmp\bpu\but\bte\be i\bin\bns\bst\bta\ban\bnc\bce\bes\bs\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bm_\bi_\bg _\b-_\bl_\bc_\bi _\b-_\bg_\bi _\b<_\bG_\bP_\bU _\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be _\bI_\bD_\bs_\b> _\b-_\bi _\b<_\bG_\bP_\bU _\bI_\bD_\bs_\b>\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bm_\bi_\bg _\b-_\b-_\bl_\bi_\bs_\bt_\b-_\bc_\bo_\bm_\bp_\bu_\bt_\be_\b-_\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be_\bs _\b-_\b-_\bg_\bp_\bu_\b-_\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be_\b-_\bi_\bd _\b<_\bG_\bP_\bU _\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be\n",
            "       _\bI_\bD_\bs_\b> _\b-_\b-_\bi_\bd _\b<_\bG_\bP_\bU _\bI_\bD_\bs_\b>\n",
            "\n",
            "       Lists compute instances and their IDs.\n",
            "\n",
            "       1\b14\b4)\b) D\bDe\bes\bst\btr\bro\boy\by c\bco\bom\bmp\bpu\but\bte\be i\bin\bns\bst\bta\ban\bnc\bce\be\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi  _\bm_\bi_\bg  _\b-_\bd_\bc_\bi _\b-_\bc_\bi _\b<_\bc_\bo_\bm_\bp_\bu_\bt_\be _\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be _\bI_\bD_\bs_\b> _\b-_\bg_\bi _\b<_\bG_\bP_\bU _\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be _\bI_\bD_\bs_\b>\n",
            "       _\b-_\bi _\b<_\bG_\bP_\bU _\bI_\bD_\bs_\b>\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bm_\bi_\bg _\b-_\b-_\bd_\be_\bs_\bt_\br_\bo_\by_\b-_\bc_\bo_\bm_\bp_\bu_\bt_\be_\b-_\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be  _\b-_\b-_\bc_\bo_\bm_\bp_\bu_\bt_\be_\b-_\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be_\b-_\bi_\bd  _\b<_\bc_\bo_\bm_\b‐\n",
            "       _\bp_\bu_\bt_\be _\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be _\bI_\bD_\bs_\b> _\b-_\b-_\bg_\bp_\bu_\b-_\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be_\b-_\bi_\bd _\b<_\bG_\bP_\bU _\bi_\bn_\bs_\bt_\ba_\bn_\bc_\be _\bI_\bD_\bs_\b> _\b-_\b-_\bi_\bd _\b<_\bG_\bP_\bU _\bI_\bD_\bs_\b>\n",
            "\n",
            "       Destroys  compute instances. The command fails if the requested compute\n",
            "       instance is in use by an application.\n",
            "\n",
            "   B\bBo\boo\bos\bst\bt S\bSl\bli\bid\bde\ber\br\n",
            "       The privileged \"nvidia-smi boost-slider\" command-line is used to manage\n",
            "       boost  slider  on  GPUs.  It provides options to list and control boost\n",
            "       sliders.\n",
            "\n",
            "       U\bUs\bsa\bag\bge\be:\b:\n",
            "\n",
            "       1\b1)\b) D\bDi\bis\bsp\bpl\bla\bay\by h\bhe\bel\blp\bp m\bme\ben\bnu\bu\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bb_\bo_\bo_\bs_\bt_\b-_\bs_\bl_\bi_\bd_\be_\br _\b-_\bh\n",
            "\n",
            "       Displays help menu for using the command-line.\n",
            "\n",
            "       2\b2)\b) L\bLi\bis\bst\bt o\bon\bne\be o\bor\br m\bmo\bor\bre\be G\bGP\bPU\bUs\bs\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bb_\bo_\bo_\bs_\bt_\b-_\bs_\bl_\bi_\bd_\be_\br _\b-_\bi _\b<_\bG_\bP_\bU _\bI_\bD_\bs_\b>\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bb_\bo_\bo_\bs_\bt_\b-_\bs_\bl_\bi_\bd_\be_\br _\b-_\b-_\bi_\bd _\b<_\bG_\bP_\bU _\bI_\bD_\bs_\b>\n",
            "\n",
            "       Selects one or more GPUs using the given comma-separated  GPU  indexes,\n",
            "       PCI  bus  IDs  or  UUIDs.  If  not  used, the given command-line option\n",
            "       applies to all of the supported GPUs.\n",
            "\n",
            "       3\b3)\b) L\bLi\bis\bst\bt b\bbo\boo\bos\bst\bt s\bsl\bli\bid\bde\ber\brs\bs\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bb_\bo_\bo_\bs_\bt_\b-_\bs_\bl_\bi_\bd_\be_\br _\b-_\bl\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bb_\bo_\bo_\bs_\bt_\b-_\bs_\bl_\bi_\bd_\be_\br _\b-_\b-_\bl_\bi_\bs_\bt\n",
            "\n",
            "       List all boost sliders for the selected devices.\n",
            "\n",
            "       4\b4)\b) S\bSe\bet\bt v\bvi\bid\bde\beo\bo b\bbo\boo\bos\bst\bt s\bsl\bli\bid\bde\ber\br\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bb_\bo_\bo_\bs_\bt_\b-_\bs_\bl_\bi_\bd_\be_\br _\b-_\b-_\bv_\bb_\bo_\bo_\bs_\bt _\b<_\bv_\ba_\bl_\bu_\be_\b>\n",
            "\n",
            "       Set the video boost slider for the selected devices.\n",
            "\n",
            "   P\bPo\bow\bwe\ber\br H\bHi\bin\bnt\bt\n",
            "       The privileged \"nvidia-smi power-hint\" command-line is  used  to  query\n",
            "       power hint on GPUs.\n",
            "\n",
            "       U\bUs\bsa\bag\bge\be:\b:\n",
            "\n",
            "       1\b1)\b) D\bDi\bis\bsp\bpl\bla\bay\by h\bhe\bel\blp\bp m\bme\ben\bnu\bu\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bb_\bo_\bo_\bs_\bt_\b-_\bs_\bl_\bi_\bd_\be_\br _\b-_\bh\n",
            "\n",
            "       Displays help menu for using the command-line.\n",
            "\n",
            "       2\b2)\b) L\bLi\bis\bst\bt o\bon\bne\be o\bor\br m\bmo\bor\bre\be G\bGP\bPU\bUs\bs\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bb_\bo_\bo_\bs_\bt_\b-_\bs_\bl_\bi_\bd_\be_\br _\b-_\bi _\b<_\bG_\bP_\bU _\bI_\bD_\bs_\b>\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bb_\bo_\bo_\bs_\bt_\b-_\bs_\bl_\bi_\bd_\be_\br _\b-_\b-_\bi_\bd _\b<_\bG_\bP_\bU _\bI_\bD_\bs_\b>\n",
            "\n",
            "       Selects  one  or more GPUs using the given comma-separated GPU indexes,\n",
            "       PCI bus IDs or UUIDs.  If  not  used,  the  given  command-line  option\n",
            "       applies to all of the supported GPUs.\n",
            "\n",
            "       3\b3)\b) L\bLi\bis\bst\bt p\bpo\bow\bwe\ber\br h\bhi\bin\bnt\bt i\bin\bnf\bfo\bo\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bb_\bo_\bo_\bs_\bt_\b-_\bs_\bl_\bi_\bd_\be_\br _\b-_\bl\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bb_\bo_\bo_\bs_\bt_\b-_\bs_\bl_\bi_\bd_\be_\br _\b-_\b-_\bl_\bi_\bs_\bt_\b-_\bi_\bn_\bf_\bo\n",
            "\n",
            "       List all boost sliders for the selected devices.\n",
            "\n",
            "       4\b4)\b) Q\bQu\bue\ber\bry\by p\bpo\bow\bwe\ber\br h\bhi\bin\bnt\bt\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bb_\bo_\bo_\bs_\bt_\b-_\bs_\bl_\bi_\bd_\be_\br _\b-_\bg_\bc _\b<_\bv_\ba_\bl_\bu_\be_\b> _\b-_\bt _\b<_\bv_\ba_\bl_\bu_\be_\b> _\b-_\bp _\b<_\bp_\br_\bo_\bf_\bi_\bl_\be _\bI_\bD_\b>\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi  _\bb_\bo_\bo_\bs_\bt_\b-_\bs_\bl_\bi_\bd_\be_\br _\b-_\b-_\bg_\br_\ba_\bp_\bh_\bi_\bc_\bs_\b-_\bc_\bl_\bo_\bc_\bk _\b<_\bv_\ba_\bl_\bu_\be_\b> _\b-_\b-_\bt_\be_\bm_\bp_\be_\br_\ba_\bt_\bu_\br_\be _\b<_\bv_\ba_\bl_\bu_\be_\b>\n",
            "       _\b-_\b-_\bp_\br_\bo_\bf_\bi_\bl_\be _\b<_\bp_\br_\bo_\bf_\bi_\bl_\be _\bI_\bD_\b>\n",
            "\n",
            "       Query power hint with graphics clock, temperature and profile id.\n",
            "\n",
            "       5\b5)\b) Q\bQu\bue\ber\bry\by p\bpo\bow\bwe\ber\br h\bhi\bin\bnt\bt\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bb_\bo_\bo_\bs_\bt_\b-_\bs_\bl_\bi_\bd_\be_\br _\b-_\bg_\bc _\b<_\bv_\ba_\bl_\bu_\be_\b> _\b-_\bm_\bc _\b<_\bv_\ba_\bl_\bu_\be_\b> _\b-_\bt _\b<_\bv_\ba_\bl_\bu_\be_\b> _\b-_\bp  _\b<_\bp_\br_\bo_\bf_\bi_\bl_\be\n",
            "       _\bI_\bD_\b>\n",
            "\n",
            "       _\bn_\bv_\bi_\bd_\bi_\ba_\b-_\bs_\bm_\bi _\bb_\bo_\bo_\bs_\bt_\b-_\bs_\bl_\bi_\bd_\be_\br _\b-_\b-_\bg_\br_\ba_\bp_\bh_\bi_\bc_\bs_\b-_\bc_\bl_\bo_\bc_\bk _\b<_\bv_\ba_\bl_\bu_\be_\b> _\b-_\b-_\bm_\be_\bm_\bo_\br_\by_\b-_\bc_\bl_\bo_\bc_\bk _\b<_\bv_\ba_\bl_\bu_\be_\b>\n",
            "       _\b-_\b-_\bt_\be_\bm_\bp_\be_\br_\ba_\bt_\bu_\br_\be _\b<_\bv_\ba_\bl_\bu_\be_\b> _\b-_\b-_\bp_\br_\bo_\bf_\bi_\bl_\be _\b<_\bp_\br_\bo_\bf_\bi_\bl_\be _\bI_\bD_\b>\n",
            "\n",
            "       Query power hint with graphics clock,  memory  clock,  temperature  and\n",
            "       profile id.\n",
            "\n",
            "U\bUN\bNI\bIT\bT A\bAT\bTT\bTR\bRI\bIB\bBU\bUT\bTE\bES\bS\n",
            "       The  following  list  describes all possible data returned by the -\b-q\bq -\b-u\bu\n",
            "       unit query option.  Unless otherwise noted all  numerical  results  are\n",
            "       base 10 and unitless.\n",
            "\n",
            "   T\bTi\bim\bme\bes\bst\bta\bam\bmp\bp\n",
            "       The  current system timestamp at the time nvidia-smi was invoked.  For‐\n",
            "       mat is \"Day-of-week Month Day HH:MM:SS Year\".\n",
            "\n",
            "   D\bDr\bri\biv\bve\ber\br V\bVe\ber\brs\bsi\bio\bon\bn\n",
            "       The  version  of  the  installed  NVIDIA  display  driver.   Format  is\n",
            "       \"Major-Number.Minor-Number\".\n",
            "\n",
            "   H\bHI\bIC\bC I\bIn\bnf\bfo\bo\n",
            "       Information  about any Host Interface Cards (HIC) that are installed in\n",
            "       the system.\n",
            "\n",
            "       F\bFi\bir\brm\bmw\bwa\bar\bre\be V\bVe\ber\brs\bsi\bio\bon\bn\n",
            "                      The version of the firmware running on the HIC.\n",
            "\n",
            "   A\bAt\btt\bta\bac\bch\bhe\bed\bd U\bUn\bni\bit\bts\bs\n",
            "       The number of attached Units in the system.\n",
            "\n",
            "   P\bPr\bro\bod\bdu\buc\bct\bt N\bNa\bam\bme\be\n",
            "       The official product name of the unit.  This is an alphanumeric  value.\n",
            "       For all S-class products.\n",
            "\n",
            "   P\bPr\bro\bod\bdu\buc\bct\bt I\bId\bd\n",
            "       The  product identifier for the unit.  This is an alphanumeric value of\n",
            "       the form \"part1-part2-part3\".  For all S-class products.\n",
            "\n",
            "   P\bPr\bro\bod\bdu\buc\bct\bt S\bSe\ber\bri\bia\bal\bl\n",
            "       The immutable globally unique identifier for  the  unit.   This  is  an\n",
            "       alphanumeric value.  For all S-class products.\n",
            "\n",
            "   F\bFi\bir\brm\bmw\bwa\bar\bre\be V\bVe\ber\brs\bsi\bio\bon\bn\n",
            "       The version of the firmware running on the unit.  Format is \"Major-Num‐\n",
            "       ber.Minor-Number\".  For all S-class products.\n",
            "\n",
            "   L\bLE\bED\bD S\bSt\bta\bat\bte\be\n",
            "       The LED indicator is used to flag systems with potential problems.   An\n",
            "       LED color of AMBER indicates an issue.  For all S-class products.\n",
            "\n",
            "       C\bCo\bol\blo\bor\br          The  color  of  the  LED  indicator.   Either \"GREEN\" or\n",
            "                      \"AMBER\".\n",
            "\n",
            "       C\bCa\bau\bus\bse\be          The reason for the current LED color.  The cause may  be\n",
            "                      listed as any combination of \"Unknown\", \"Set to AMBER by\n",
            "                      host system\", \"Thermal sensor  failure\",  \"Fan  failure\"\n",
            "                      and \"Temperature exceeds critical limit\".\n",
            "\n",
            "   T\bTe\bem\bmp\bpe\ber\bra\bat\btu\bur\bre\be\n",
            "       Temperature  readings  for important components of the Unit.  All read‐\n",
            "       ings are in degrees C.  Not all readings may be available.  For all  S-\n",
            "       class products.\n",
            "\n",
            "       I\bIn\bnt\bta\bak\bke\be         Air temperature at the unit intake.\n",
            "\n",
            "       E\bEx\bxh\bha\bau\bus\bst\bt        Air temperature at the unit exhaust point.\n",
            "\n",
            "       B\bBo\boa\bar\brd\bd          Air temperature across the unit board.\n",
            "\n",
            "   P\bPS\bSU\bU\n",
            "       Readings for the unit power supply.  For all S-class products.\n",
            "\n",
            "       S\bSt\bta\bat\bte\be          Operating  state of the PSU.  The power supply state can\n",
            "                      be any of the  following:  \"Normal\",  \"Abnormal\",  \"High\n",
            "                      voltage\",  \"Fan  failure\", \"Heatsink temperature\", \"Cur‐\n",
            "                      rent  limit\",  \"Voltage  below  UV   alarm   threshold\",\n",
            "                      \"Low-voltage\",  \"I2C  remote  off command\", \"MOD_DISABLE\n",
            "                      input\" or \"Short pin transition\".\n",
            "\n",
            "       V\bVo\bol\blt\bta\bag\bge\be        PSU voltage setting, in volts.\n",
            "\n",
            "       C\bCu\bur\brr\bre\ben\bnt\bt        PSU current draw, in amps.\n",
            "\n",
            "   F\bFa\ban\bn I\bIn\bnf\bfo\bo\n",
            "       Fan readings for the unit.  A reading is  provided  for  each  fan,  of\n",
            "       which there can be many.  For all S-class products.\n",
            "\n",
            "       S\bSt\bta\bat\bte\be          The state of the fan, either \"NORMAL\" or \"FAILED\".\n",
            "\n",
            "       S\bSp\bpe\bee\bed\bd          For a healthy fan, the fan's speed in RPM.\n",
            "\n",
            "   A\bAt\btt\bta\bac\bch\bhe\bed\bd G\bGP\bPU\bUs\bs\n",
            "       A  list  of PCI bus ids that correspond to each of the GPUs attached to\n",
            "       the unit.  The bus ids have the form  \"domain:bus:device.function\",  in\n",
            "       hex.  For all S-class products.\n",
            "\n",
            "N\bNO\bOT\bTE\bES\bS\n",
            "       On  Linux,  NVIDIA device files may be modified by nvidia-smi if run as\n",
            "       root.  Please see the relevant section of the driver README file.\n",
            "\n",
            "       The -\b-a\ba and -\b-g\bg arguments are now deprecated  in  favor  of  -\b-q\bq  and  -\b-i\bi,\n",
            "       respectively.  However, the old arguments still work for this release.\n",
            "\n",
            "E\bEX\bXA\bAM\bMP\bPL\bLE\bES\bS\n",
            "   n\bnv\bvi\bid\bdi\bia\ba-\b-s\bsm\bmi\bi -\b-q\bq\n",
            "       Query  attributes  for all GPUs once, and display in plain text to std‐\n",
            "       out.\n",
            "\n",
            "   n\bnv\bvi\bid\bdi\bia\ba-\b-s\bsm\bmi\bi -\b--\b-f\bfo\bor\brm\bma\bat\bt=\b=c\bcs\bsv\bv,\b,n\bno\boh\bhe\bea\bad\bde\ber\br -\b--\b-q\bqu\bue\ber\bry\by-\b-g\bgp\bpu\bu=\b=u\buu\bui\bid\bd,\b,p\bpe\ber\brs\bsi\bis\bst\bte\ben\bnc\bce\be_\b_m\bmo\bod\bde\be\n",
            "       Query UUID and persistence mode of all GPUs in the system.\n",
            "\n",
            "   n\bnv\bvi\bid\bdi\bia\ba-\b-s\bsm\bmi\bi -\b-q\bq -\b-d\bd E\bEC\bCC\bC,\b,P\bPO\bOW\bWE\bER\bR -\b-i\bi 0\b0 -\b-l\bl 1\b10\b0 -\b-f\bf o\bou\but\bt.\b.l\blo\bog\bg\n",
            "       Query ECC errors and power consumption for GPU 0 at a frequency  of  10\n",
            "       seconds, indefinitely, and record to the file out.log.\n",
            "\n",
            "   \"\b\"n\bnv\bvi\bid\bdi\bia\ba-\b-s\bsm\bmi\bi                    -\b-c\bc                    1\b1                   -\b-i\bi\n",
            "       G\bGP\bPU\bU-\b-b\bb2\b2f\bf5\b5f\bf1\b1b\bb7\b74\b45\b5e\be3\b3d\bd2\b23\b3d\bd-\b-6\b65\b5a\ba3\b3a\ba2\b26\b6d\bd-\b-0\b09\b97\b7d\bdb\bb3\b35\b58\b8-\b-7\b73\b30\b03\b3e\be0\b0b\bb6\b6-\b-1\b14\b49\b96\b64\b42\b2f\bff\bf3\b3d\bd2\b21\b19\b9f\bf8\b85\b58\b87\b7c\bcd\bde\be3\b3a\ba8\b8\"\b\"\n",
            "       Set   the   compute   mode   to   \"PROHIBITED\"   for   GPU   with  UUID\n",
            "       \"GPU-b2f5f1b745e3d23d-65a3a26d-097db358-7303e0b6-149642ff3d219f8587cde3a8\".\n",
            "\n",
            "   n\bnv\bvi\bid\bdi\bia\ba-\b-s\bsm\bmi\bi -\b-q\bq -\b-u\bu -\b-x\bx -\b--\b-d\bdt\btd\bd\n",
            "       Query  attributes  for  all  Units once, and display in XML format with\n",
            "       embedded DTD to stdout.\n",
            "\n",
            "   n\bnv\bvi\bid\bdi\bia\ba-\b-s\bsm\bmi\bi -\b--\b-d\bdt\btd\bd -\b-u\bu -\b-f\bf n\bnv\bvs\bsm\bmi\bi_\b_u\bun\bni\bit\bt.\b.d\bdt\btd\bd\n",
            "       Write the Unit DTD to nvsmi_unit.dtd.\n",
            "\n",
            "   n\bnv\bvi\bid\bdi\bia\ba-\b-s\bsm\bmi\bi -\b-q\bq -\b-d\bd S\bSU\bUP\bPP\bPO\bOR\bRT\bTE\bED\bD_\b_C\bCL\bLO\bOC\bCK\bKS\bS\n",
            "       Display supported clocks of all GPUs.\n",
            "\n",
            "   n\bnv\bvi\bid\bdi\bia\ba-\b-s\bsm\bmi\bi -\b-i\bi 0\b0 -\b--\b-a\bap\bpp\bpl\bli\bic\bca\bat\bti\bio\bon\bns\bs-\b-c\bcl\blo\boc\bck\bks\bs 2\b25\b50\b00\b0,\b,7\b74\b45\b5\n",
            "       Set applications clocks to 2500 MHz memory, and 745 MHz graphics.\n",
            "\n",
            "   n\bnv\bvi\bid\bdi\bia\ba-\b-s\bsm\bmi\bi m\bmi\big\bg -\b-c\bcg\bgi\bi 1\b19\b9\n",
            "       Create a MIG GPU instance on profile ID 19.\n",
            "\n",
            "   n\bnv\bvi\bid\bdi\bia\ba-\b-s\bsm\bmi\bi m\bmi\big\bg -\b-c\bcg\bgi\bi 1\b19\b9:\b:2\b2\n",
            "       Create a MIG GPU instance on profile ID 19 at placement start index 2.\n",
            "\n",
            "   n\bnv\bvi\bid\bdi\bia\ba-\b-s\bsm\bmi\bi b\bbo\boo\bos\bst\bt-\b-s\bsl\bli\bid\bde\ber\br -\b-l\bl\n",
            "       List all boost sliders for all GPUs.\n",
            "\n",
            "   n\bnv\bvi\bid\bdi\bia\ba-\b-s\bsm\bmi\bi b\bbo\boo\bos\bst\bt-\b-s\bsl\bli\bid\bde\ber\br -\b--\b-v\bvb\bbo\boo\bos\bst\bt 1\b1\n",
            "       Set vboost to value 1 for all GPUs.\n",
            "\n",
            "   n\bnv\bvi\bid\bdi\bia\ba-\b-s\bsm\bmi\bi p\bpo\bow\bwe\ber\br-\b-h\bhi\bin\bnt\bt -\b-l\bl\n",
            "       List clock range, temperature range and  supported  profiles  of  power\n",
            "       hint.\n",
            "\n",
            "   n\bnv\bvi\bid\bdi\bia\ba-\b-s\bsm\bmi\bi b\bbo\boo\bos\bst\bt-\b-s\bsl\bli\bid\bde\ber\br -\b-g\bgc\bc 1\b13\b35\b50\b0 -\b-t\bt 6\b60\b0 -\b-p\bp 0\b0\n",
            "       Query power hint with graphics clock at 1350MHz, temperature at 60C and\n",
            "       profile ID at 0.\n",
            "\n",
            "   n\bnv\bvi\bid\bdi\bia\ba-\b-s\bsm\bmi\bi b\bbo\boo\bos\bst\bt-\b-s\bsl\bli\bid\bde\ber\br -\b-g\bgc\bc 1\b13\b35\b50\b0 -\b-m\bmc\bc 1\b12\b21\b15\b5 -\b-t\bt n\bn5\b5 -\b-p\bp 1\b1\n",
            "       Query power hint with  graphics  clock  at  1350MHz,  memory  clock  at\n",
            "       1215MHz, temperature at -5C and profile ID at 1.\n",
            "\n",
            "C\bCH\bHA\bAN\bNG\bGE\bE L\bLO\bOG\bG\n",
            "         === Known Issues ===\n",
            "\n",
            "         *  On  Linux  GPU  Reset can't be triggered when there is pending GOM\n",
            "       change.\n",
            "\n",
            "         * On Linux GPU Reset may not successfully change pending ECC mode.  A\n",
            "       full reboot may be required to enable the mode change.\n",
            "\n",
            "         *  On  Linux  platforms  that  configure  NVIDIA  GPUs as NUMA nodes,\n",
            "       enabling persistence mode or resetting GPUs may print \"Warning: persis‐\n",
            "       tence  mode  is  disabled on device\" if nvidia-persistenced is not run‐\n",
            "       ning, or if nvidia-persistenced  cannot  access  files  in  the  NVIDIA\n",
            "       driver's procfs directory for the device (/proc/driver/nvidia/gpus/<PCI\n",
            "       Config Address>/). During GPU reset and driver reload,  this  directory\n",
            "       will  be  deleted  and  recreated,  and  outstanding  references to the\n",
            "       deleted directory, such as mounts or shells, can prevent processes from\n",
            "       accessing files in the new directory.\n",
            "\n",
            "         *  === Changes between nvidia-smi v465 Update and v470 ===\n",
            "\n",
            "         * Added support to query power hint\n",
            "\n",
            "         *  === Changes between nvidia-smi v460 Update and v465 ===\n",
            "\n",
            "         * Removed support for -acp,--application-clock-permissions option\n",
            "\n",
            "         *  === Changes between nvidia-smi v450 Update and v460 ===\n",
            "\n",
            "         * Add option to specify placement when creating a MIG GPU instance.\n",
            "\n",
            "         * Added support to query and control boost slider\n",
            "\n",
            "         *  === Changes between nvidia-smi v445 Update and v450 ===\n",
            "\n",
            "         *  Added --lock-memory-clock and --reset-memory-clock command to lock\n",
            "       to closest min/max Memory clock provided and ability  to  reset  Memory\n",
            "       clock\n",
            "\n",
            "         * Allow fan speeds greater than 100% to be reported\n",
            "\n",
            "         * Added topo support to display NUMA node affinity for GPU devices\n",
            "\n",
            "         * Added support to create MIG instances using profile names\n",
            "\n",
            "         * Added support to create the default compute instance while creating\n",
            "       a GPU instance\n",
            "\n",
            "         * Added support to query and disable MIG mode on Windows\n",
            "\n",
            "         * Removed support of GPU reset(-r) command on MIG enabled vGPU guests\n",
            "\n",
            "         *  === Changes between nvidia-smi v418 Update and v445 ===\n",
            "\n",
            "         * Added support for Multi Instance GPU (MIG)\n",
            "\n",
            "         * Added support to individually reset NVLink-capable  GPUs  based  on\n",
            "       the NVIDIA Ampere architecture\n",
            "\n",
            "         *  === Changes between nvidia-smi v361 Update and v418 ===\n",
            "\n",
            "         *  Support for Volta and Turing architectures, bug fixes, performance\n",
            "       improvements, and new features\n",
            "\n",
            "         *  === Changes between nvidia-smi v352 Update and v361 ===\n",
            "\n",
            "         * Added nvlink support to expose the publicly available  NVLINK  NVML\n",
            "       APIs\n",
            "\n",
            "         * Added clocks sub-command with synchronized boost support\n",
            "\n",
            "         * Updated nvidia-smi stats to report GPU temperature metric\n",
            "\n",
            "         * Updated nvidia-smi dmon to support PCIe throughput\n",
            "\n",
            "         * Updated nvidia-smi daemon/replay to support PCIe throughput\n",
            "\n",
            "         *  Updated  nvidia-smi dmon, daemon and replay to support PCIe Replay\n",
            "       Errors\n",
            "\n",
            "         * Added GPU part numbers in nvidia-smi -q\n",
            "\n",
            "         * Removed support for exclusive thread compute mode\n",
            "\n",
            "         * Added Video (encoder/decode) clocks to the Clocks  and  Max  Clocks\n",
            "       display of nvidia-smi -q\n",
            "\n",
            "         * Added memory temperature output to nvidia-smi dmon\n",
            "\n",
            "         *  Added  --lock-gpu-clock  and  --reset-gpu-clock command to lock to\n",
            "       closest min/max GPU clock provided and reset clock\n",
            "\n",
            "         * Added --cuda-clocks to override or restore default CUDA clocks\n",
            "\n",
            "         === Changes between nvidia-smi v346 Update and v352 ===\n",
            "\n",
            "         * Added topo support to display affinities per GPU\n",
            "\n",
            "         * Added topo support to display neighboring GPUs for a given level\n",
            "\n",
            "         * Added topo support to show pathway between two given GPUs\n",
            "\n",
            "         * Added \"nvidia-smi pmon\"  command-line  for  process  monitoring  in\n",
            "       scrolling format\n",
            "\n",
            "         * Added \"--debug\" option to produce an encrypted debug log for use in\n",
            "       submission of bugs back to NVIDIA\n",
            "\n",
            "         * Fixed reporting of Used/Free memory under Windows WDDM mode\n",
            "\n",
            "         * The accounting stats is updated to include both running and  termi‐\n",
            "       nated processes. The execution time of running process is reported as 0\n",
            "       and updated to actual value when the process is terminated.\n",
            "\n",
            "         === Changes between nvidia-smi v340 Update and v346 ===\n",
            "\n",
            "         * Added reporting of PCIe replay counters\n",
            "\n",
            "         * Added support for reporting Graphics processes via nvidia-smi\n",
            "\n",
            "         * Added reporting of PCIe utilization\n",
            "\n",
            "         * Added dmon command-line for device monitoring in scrolling format\n",
            "\n",
            "         * Added daemon command-line to run in background and monitor  devices\n",
            "       as a daemon process. Generates dated log files at /var/log/nvstats/\n",
            "\n",
            "         *  Added  replay command-line to replay/extract the stat files gener‐\n",
            "       ated by the daemon tool\n",
            "\n",
            "         === Changes between nvidia-smi v331 Update and v340 ===\n",
            "\n",
            "         * Added reporting of temperature threshold information.\n",
            "\n",
            "         * Added reporting of brand information (e.g. Tesla, Quadro, etc.)\n",
            "\n",
            "         * Added support for K40d and K80.\n",
            "\n",
            "         * Added reporting of max, min and avg for  samples  (power,  utiliza‐\n",
            "       tion,  clock changes). Example commandline: nvidia-smi -q -d power,uti‐\n",
            "       lization, clock\n",
            "\n",
            "         * Added nvidia-smi stats interface  to  collect  statistics  such  as\n",
            "       power, utilization, clock changes, xid events and perf capping counters\n",
            "       with a notion of time attached to  each  sample.  Example  commandline:\n",
            "       nvidia-smi stats\n",
            "\n",
            "         *  Added  support for collectively reporting metrics on more than one\n",
            "       GPU. Used with comma separated with \"-i\" option. Example: nvidia-smi -i\n",
            "       0,1,2\n",
            "\n",
            "         *  Added  support for displaying the GPU encoder and decoder utiliza‐\n",
            "       tions\n",
            "\n",
            "         * Added nvidia-smi topo interface to display the GPUDirect communica‐\n",
            "       tion matrix (EXPERIMENTAL)\n",
            "\n",
            "         *  Added support for displayed the GPU board ID and whether or not it\n",
            "       is a multiGPU board\n",
            "\n",
            "         * Removed user-defined throttle reason from XML output\n",
            "\n",
            "         === Changes between nvidia-smi v5.319 Update and v331 ===\n",
            "\n",
            "         * Added reporting of minor number.\n",
            "\n",
            "         * Added reporting BAR1 memory size.\n",
            "\n",
            "         * Added reporting of bridge chip firmware.\n",
            "\n",
            "         === Changes between nvidia-smi v4.319 Production  and  v4.319  Update\n",
            "       ===\n",
            "\n",
            "         * Added new --applications-clocks-permission switch to change permis‐\n",
            "       sion requirements for setting and resetting applications clocks.\n",
            "\n",
            "         === Changes between nvidia-smi v4.304 and v4.319 Production ===\n",
            "\n",
            "         * Added reporting of Display Active state and  updated  documentation\n",
            "       to clarify how it differs from Display Mode and Display Active state\n",
            "\n",
            "         *  For  consistency on multi-GPU boards nvidia-smi -L always displays\n",
            "       UUID instead of serial number\n",
            "\n",
            "         * Added machine readable selective  reporting.  See  SELECTIVE  QUERY\n",
            "       OPTIONS section of nvidia-smi -h\n",
            "\n",
            "         *  Added  queries for page retirement information.  See --help-query-\n",
            "       retired-pages and -d PAGE_RETIREMENT\n",
            "\n",
            "         * Renamed Clock Throttle Reason User Defined Clocks  to  Applications\n",
            "       Clocks Setting\n",
            "\n",
            "         * On error, return codes have distinct non zero values for each error\n",
            "       class. See RETURN VALUE section\n",
            "\n",
            "         * nvidia-smi -i can now query information from healthy GPU when there\n",
            "       is a problem with other GPU in the system\n",
            "\n",
            "         * All messages that point to a problem with a GPU print pci bus id of\n",
            "       a GPU at fault\n",
            "\n",
            "         * New flag --loop-ms for querying information at  higher  rates  than\n",
            "       once a second (can have negative impact on system performance)\n",
            "\n",
            "         * Added queries for accounting procsses.  See --help-query-accounted-\n",
            "       apps and -d ACCOUNTING\n",
            "\n",
            "         * Added the enforced power limit to the query output\n",
            "\n",
            "         === Changes between nvidia-smi v4.304 RC and v4.304 Production ===\n",
            "\n",
            "         * Added reporting of GPU Operation Mode (GOM)\n",
            "\n",
            "         * Added new --gom switch to set GPU Operation Mode\n",
            "\n",
            "         === Changes between nvidia-smi v3.295 and v4.304 RC ===\n",
            "\n",
            "         * Reformatted non-verbose output due to user feedback.  Removed pend‐\n",
            "       ing information from table.\n",
            "\n",
            "         *  Print  out  helpful  message if initialization fails due to kernel\n",
            "       module not receiving interrupts\n",
            "\n",
            "         * Better error handling when NVML shared library is  not  present  in\n",
            "       the system\n",
            "\n",
            "         * Added new --applications-clocks switch\n",
            "\n",
            "         *  Added new filter to --display switch. Run with -d SUPPORTED_CLOCKS\n",
            "       to list possible clocks on a GPU\n",
            "\n",
            "         * When reporting free memory, calculate it from the rounded total and\n",
            "       used memory so that values add up\n",
            "\n",
            "         *  Added  reporting of power management limit constraints and default\n",
            "       limit\n",
            "\n",
            "         * Added new --power-limit switch\n",
            "\n",
            "         * Added reporting of texture memory ECC errors\n",
            "\n",
            "         * Added reporting of Clock Throttle Reasons\n",
            "\n",
            "         === Changes between nvidia-smi v2.285 and v3.295 ===\n",
            "\n",
            "         * Clearer error reporting for running commands (like changing compute\n",
            "       mode)\n",
            "\n",
            "         *  When  running  commands  on  multiple  GPUs at once N/A errors are\n",
            "       treated as warnings.\n",
            "\n",
            "         * nvidia-smi -i now also supports UUID\n",
            "\n",
            "         * UUID format changed to match UUID standard and will report  a  dif‐\n",
            "       ferent value.\n",
            "\n",
            "         === Changes between nvidia-smi v2.0 and v2.285 ===\n",
            "\n",
            "         * Report VBIOS version.\n",
            "\n",
            "         * Added -d/--display flag to filter parts of data\n",
            "\n",
            "         * Added reporting of PCI Sub System ID\n",
            "\n",
            "         * Updated docs to indicate we support M2075 and C2075\n",
            "\n",
            "         * Report HIC HWBC firmware version with -u switch\n",
            "\n",
            "         * Report max(P0) clocks next to current clocks\n",
            "\n",
            "         * Added --dtd flag to print the device or unit DTD\n",
            "\n",
            "         * Added message when NVIDIA driver is not running\n",
            "\n",
            "         * Added reporting of PCIe link generation (max and current), and link\n",
            "       width (max and current).\n",
            "\n",
            "         * Getting pending driver model works on non-admin\n",
            "\n",
            "         * Added support for running nvidia-smi on Windows Guest accounts\n",
            "\n",
            "         * Running nvidia-smi without -q command will output non verbose  ver‐\n",
            "       sion of -q instead of help\n",
            "\n",
            "         *  Fixed  parsing  of  -l/--loop=  argument (default value, 0, to big\n",
            "       value)\n",
            "\n",
            "         * Changed format of pciBusId (to XXXX:XX:XX.X - this change was visi‐\n",
            "       ble in 280)\n",
            "\n",
            "         *  Parsing  of busId for -i command is less restrictive. You can pass\n",
            "       0:2:0.0 or 0000:02:00 and other variations\n",
            "\n",
            "         * Changed versioning scheme to also include \"driver version\"\n",
            "\n",
            "         * XML format always conforms to DTD, even when error conditions occur\n",
            "\n",
            "         * Added support for single and double bit ECC events and  XID  errors\n",
            "       (enabled by default with -l flag disabled for -x flag)\n",
            "\n",
            "         * Added device reset -r --gpu-reset flags\n",
            "\n",
            "         * Added listing of compute running processes\n",
            "\n",
            "         * Renamed power state to performance state. Deprecated support exists\n",
            "       in XML output only.\n",
            "\n",
            "         * Updated DTD version number to 2.0 to match the updated XML output\n",
            "\n",
            "S\bSE\bEE\bE A\bAL\bLS\bSO\bO\n",
            "       On     Linux,     the     driver     README     is     installed     as\n",
            "       /usr/share/doc/NVIDIA_GLX-1.0/README.txt\n",
            "\n",
            "A\bAU\bUT\bTH\bHO\bOR\bR\n",
            "       NVIDIA Corporation\n",
            "\n",
            "C\bCO\bOP\bPY\bYR\bRI\bIG\bGH\bHT\bT\n",
            "       Copyright 2011-2021 NVIDIA Corporation.\n",
            "\n",
            "nvidia-smi 470.74                  2021/9/13                     nvidia-smi(1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCzJSxmbD7Xq",
        "outputId": "cc9ecdf0-f86b-4a95-c5ef-a268aa23a909",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Wed_Oct_23_19:24:38_PDT_2019\n",
            "Cuda compilation tools, release 10.2, V10.2.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E5tP3_xEWg1",
        "outputId": "9cb57495-72f1-4665-90ad-9b50382624d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile add.cpp\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "\n",
        "// function to add the elements of two arrays\n",
        "void add(int n, float *x, float *y)\n",
        "{\n",
        "  for (int i = 0; i < n; i++)\n",
        "      y[i] = x[i] + y[i];\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "  int N = 1<<20; // 1M elements\n",
        "\n",
        "  float *x = new float[N];\n",
        "  float *y = new float[N];\n",
        "\n",
        "  // initialize x and y arrays on the host\n",
        "  for (int i = 0; i < N; i++) {\n",
        "    x[i] = 1.0f;\n",
        "    y[i] = 2.0f;\n",
        "  }\n",
        "\n",
        "  // Run kernel on 1M elements on the CPU\n",
        "  add(N, x, y);\n",
        "\n",
        "  // Check for errors (all values should be 3.0f)\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < N; i++)\n",
        "    maxError = fmax(maxError, fabs(y[i]-3.0f));\n",
        "  std::cout << \"Max error: \" << maxError << std::endl;\n",
        "\n",
        "  // Free memory\n",
        "  delete [] x;\n",
        "  delete [] y;\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing add.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdFRv11KFBiO",
        "outputId": "3f6dd160-8260-4c20-dbd0-72c95f94dcd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 8\n",
            "-rw-r--r-- 1 root root  730 Oct 22 23:18 add.cpp\n",
            "drwxr-xr-x 1 root root 4096 Oct  8 13:45 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqiZaaQmFEDL"
      },
      "source": [
        "!nvcc -o add add.cpp"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd9dRHhOFO0z",
        "outputId": "ab62e7a4-66f6-4fe8-a9ae-f25d400d9cd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!time ./add"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max error: 0\n",
            "\n",
            "real\t0m0.030s\n",
            "user\t0m0.023s\n",
            "sys\t0m0.006s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg5hOCYGJSp7",
        "outputId": "76c29e53-40a5-4fb3-8f5e-b381ee314dde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile add.cu\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "// Kernel function to add the elements of two arrays\n",
        "__global__\n",
        "void add(int n, float *x, float *y)\n",
        "{\n",
        "  for (int i = 0; i < n; i++)\n",
        "    y[i] = x[i] + y[i];\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "  int N = 1<<20;\n",
        "  float *x, *y;\n",
        "\n",
        "  // Allocate Unified Memory – accessible from CPU or GPU\n",
        "  cudaMallocManaged(&x, N*sizeof(float));\n",
        "  cudaMallocManaged(&y, N*sizeof(float));\n",
        "\n",
        "  // initialize x and y arrays on the host\n",
        "  for (int i = 0; i < N; i++) {\n",
        "    x[i] = 1.0f;\n",
        "    y[i] = 2.0f;\n",
        "  }\n",
        "\n",
        "  // Run kernel on 1M elements on the GPU\n",
        "  add<<<1, 1>>>(N, x, y);\n",
        "\n",
        "  // Wait for GPU to finish before accessing on host\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // Check for errors (all values should be 3.0f)\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < N; i++)\n",
        "    maxError = fmax(maxError, fabs(y[i]-3.0f));\n",
        "  std::cout << \"Max error: \" << maxError << std::endl;\n",
        "\n",
        "  // Free memory\n",
        "  cudaFree(x);\n",
        "  cudaFree(y);\n",
        "  \n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trbzAHtIJqX4",
        "outputId": "81eea0b2-9c50-4381-ee25-f7698c9cb7d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 656\n",
            "-rwxr-xr-x 1 root root 656648 Oct 22 23:18 add\n",
            "-rw-r--r-- 1 root root    730 Oct 22 23:18 add.cpp\n",
            "-rw-r--r-- 1 root root    929 Oct 22 23:24 add.cu\n",
            "drwxr-xr-x 1 root root   4096 Oct  8 13:45 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BZkXUQDJvvn"
      },
      "source": [
        "!nvcc -o add_cuda add.cu"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vVPbHCHJ00t",
        "outputId": "8027d62d-cba6-49fa-bd7f-9fed907826c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof ./add_cuda"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==935== NVPROF is profiling process 935, command: ./add_cuda\n",
            "==935== Warning: Auto boost enabled on device 0. Profiling results may be inconsistent.\n",
            "Max error: 0\n",
            "==935== Profiling application: ./add_cuda\n",
            "==935== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  424.68ms         1  424.68ms  424.68ms  424.68ms  add(int, float*, float*)\n",
            "      API calls:   57.23%  424.71ms         1  424.71ms  424.71ms  424.71ms  cudaDeviceSynchronize\n",
            "                   42.17%  312.97ms         2  156.48ms  774.44us  312.19ms  cudaMallocManaged\n",
            "                    0.23%  1.6865ms         1  1.6865ms  1.6865ms  1.6865ms  cudaLaunchKernel\n",
            "                    0.15%  1.0966ms         2  548.30us  510.19us  586.41us  cudaFree\n",
            "                    0.11%  783.12us         1  783.12us  783.12us  783.12us  cuDeviceGetPCIBusId\n",
            "                    0.08%  563.08us         1  563.08us  563.08us  563.08us  cuDeviceTotalMem\n",
            "                    0.03%  244.75us        97  2.5230us     162ns  112.69us  cuDeviceGetAttribute\n",
            "                    0.01%  44.473us         1  44.473us  44.473us  44.473us  cuDeviceGetName\n",
            "                    0.00%  2.3520us         3     784ns     252ns  1.2340us  cuDeviceGetCount\n",
            "                    0.00%  2.1020us         2  1.0510us     445ns  1.6570us  cuDeviceGet\n",
            "                    0.00%     287ns         1     287ns     287ns     287ns  cuDeviceGetUuid\n",
            "\n",
            "==935== Unified Memory profiling result:\n",
            "Device \"Tesla K80 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "       6  1.3333MB  896.00KB  2.0000MB  8.000000MB  1.182592ms  Host To Device\n",
            "     102  120.47KB  4.0000KB  0.9961MB  12.00000MB  1.793408ms  Device To Host\n",
            "Total CPU Page faults: 51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HinwxY7S7ENf",
        "outputId": "6e0a2765-4366-4e0e-8cd1-4e64c625968c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!time ./add_cuda"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max error: 0\n",
            "\n",
            "real\t0m0.618s\n",
            "user\t0m0.438s\n",
            "sys\t0m0.160s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYgDeyOsKWIB",
        "outputId": "885c1185-16d3-48b3-a3b0-f72e17f003ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile add_block.cu\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "// Kernel function to add the elements of two arrays\n",
        "__global__\n",
        "void add(int n, float *x, float *y)\n",
        "{\n",
        "  int index = threadIdx.x;\n",
        "  int stride = blockDim.x;\n",
        "  for (int i = index; i < n; i += stride)\n",
        "      y[i] = x[i] + y[i];\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "  int N = 1<<20;\n",
        "  float *x, *y;\n",
        "\n",
        "  // Allocate Unified Memory – accessible from CPU or GPU\n",
        "  cudaMallocManaged(&x, N*sizeof(float));\n",
        "  cudaMallocManaged(&y, N*sizeof(float));\n",
        "\n",
        "  // initialize x and y arrays on the host\n",
        "  for (int i = 0; i < N; i++) {\n",
        "    x[i] = 1.0f;\n",
        "    y[i] = 2.0f;\n",
        "  }\n",
        "\n",
        "  // Run kernel on 1M elements on the GPU\n",
        "  add<<<1, 256>>>(N, x, y);\n",
        "\n",
        "  // Wait for GPU to finish before accessing on host\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // Check for errors (all values should be 3.0f)\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < N; i++)\n",
        "    maxError = fmax(maxError, fabs(y[i]-3.0f));\n",
        "  std::cout << \"Max error: \" << maxError << std::endl;\n",
        "\n",
        "  // Free memory\n",
        "  cudaFree(x);\n",
        "  cudaFree(y);\n",
        "  \n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing add_block.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pdhV9CjKk3p"
      },
      "source": [
        "!nvcc -o add_block add_block.cu"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkRQyCpLKo8f",
        "outputId": "df653597-3bb9-462f-f0ec-f738ae977b5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof ./add_block"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==1039== NVPROF is profiling process 1039, command: ./add_block\n",
            "==1039== Warning: Auto boost enabled on device 0. Profiling results may be inconsistent.\n",
            "Max error: 0\n",
            "==1039== Profiling application: ./add_block\n",
            "==1039== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  2.3551ms         1  2.3551ms  2.3551ms  2.3551ms  add(int, float*, float*)\n",
            "      API calls:   97.49%  208.68ms         2  104.34ms  682.40us  208.00ms  cudaMallocManaged\n",
            "                    1.11%  2.3778ms         1  2.3778ms  2.3778ms  2.3778ms  cudaDeviceSynchronize\n",
            "                    0.64%  1.3728ms         1  1.3728ms  1.3728ms  1.3728ms  cudaLaunchKernel\n",
            "                    0.45%  955.55us         2  477.78us  420.52us  535.03us  cudaFree\n",
            "                    0.22%  467.60us         1  467.60us  467.60us  467.60us  cuDeviceTotalMem\n",
            "                    0.08%  170.60us        97  1.7580us     152ns  70.736us  cuDeviceGetAttribute\n",
            "                    0.01%  25.251us         1  25.251us  25.251us  25.251us  cuDeviceGetName\n",
            "                    0.00%  7.9720us         1  7.9720us  7.9720us  7.9720us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.0260us         3     675ns     240ns  1.0870us  cuDeviceGetCount\n",
            "                    0.00%  1.5470us         2     773ns     312ns  1.2350us  cuDeviceGet\n",
            "                    0.00%     297ns         1     297ns     297ns     297ns  cuDeviceGetUuid\n",
            "\n",
            "==1039== Unified Memory profiling result:\n",
            "Device \"Tesla K80 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "       6  1.3333MB  896.00KB  2.0000MB  8.000000MB  955.1360us  Host To Device\n",
            "     102  120.47KB  4.0000KB  0.9961MB  12.00000MB  1.564768ms  Device To Host\n",
            "Total CPU Page faults: 51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7V-Cd0xK9vS",
        "outputId": "707afee7-ce0b-4ac1-8590-eee4c11a7123",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!time ./add_block"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max error: 0\n",
            "\n",
            "real\t0m0.179s\n",
            "user\t0m0.025s\n",
            "sys\t0m0.144s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGZzE7D_LEld"
      },
      "source": [
        "!time ./add_cuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbZAPRpkLIHn",
        "outputId": "545abd50-f456-457c-8be2-e7879995050b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile add2.cu\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "// Kernel function to add the elements of two arrays\n",
        "__global__\n",
        "void add(int n, float *x, float *y)\n",
        "{\n",
        "  int index = threadIdx.x;\n",
        "  int stride = blockDim.x;\n",
        "  for (int i = index; i < n; i += stride)\n",
        "      y[i] = x[i] + y[i];\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "  int N = 1<<20;\n",
        "  float *x, *y;\n",
        "\n",
        "  // Allocate Unified Memory – accessible from CPU or GPU\n",
        "  cudaMallocManaged(&x, N*sizeof(float));\n",
        "  cudaMallocManaged(&y, N*sizeof(float));\n",
        "\n",
        "  // initialize x and y arrays on the host\n",
        "  for (int i = 0; i < N; i++) {\n",
        "    x[i] = 1.0f;\n",
        "    y[i] = 2.0f;\n",
        "  }\n",
        "\n",
        "  // Run kernel on 1M elements on the GPU\n",
        "  add<<<1, 1>>>(N, x, y);\n",
        "\n",
        "  // Wait for GPU to finish before accessing on host\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // Check for errors (all values should be 3.0f)\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < N; i++)\n",
        "    maxError = fmax(maxError, fabs(y[i]-3.0f));\n",
        "  std::cout << \"Max error: \" << maxError << std::endl;\n",
        "\n",
        "  // Free memory\n",
        "  cudaFree(x);\n",
        "  cudaFree(y);\n",
        "  \n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing add2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMaBDJbK6bDW"
      },
      "source": [
        "!nvcc -o add2 add2.cu"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JQ8jZ6U6kJe",
        "outputId": "5bc02097-d57c-4ab3-e200-87a9a75e4d94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof ./add2"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==1111== NVPROF is profiling process 1111, command: ./add2\n",
            "==1111== Warning: Auto boost enabled on device 0. Profiling results may be inconsistent.\n",
            "Max error: 0\n",
            "==1111== Profiling application: ./add2\n",
            "==1111== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  477.82ms         1  477.82ms  477.82ms  477.82ms  add(int, float*, float*)\n",
            "      API calls:   68.07%  477.85ms         1  477.85ms  477.85ms  477.85ms  cudaDeviceSynchronize\n",
            "                   31.42%  220.60ms         2  110.30ms  759.12us  219.84ms  cudaMallocManaged\n",
            "                    0.25%  1.7273ms         1  1.7273ms  1.7273ms  1.7273ms  cudaLaunchKernel\n",
            "                    0.14%  990.62us         2  495.31us  484.85us  505.77us  cudaFree\n",
            "                    0.08%  580.70us         1  580.70us  580.70us  580.70us  cuDeviceTotalMem\n",
            "                    0.03%  238.90us        97  2.4620us     160ns  112.89us  cuDeviceGetAttribute\n",
            "                    0.00%  28.816us         1  28.816us  28.816us  28.816us  cuDeviceGetName\n",
            "                    0.00%  7.4960us         1  7.4960us  7.4960us  7.4960us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.3940us         3     798ns     242ns  1.1380us  cuDeviceGetCount\n",
            "                    0.00%  1.5940us         2     797ns     330ns  1.2640us  cuDeviceGet\n",
            "                    0.00%     319ns         1     319ns     319ns     319ns  cuDeviceGetUuid\n",
            "\n",
            "==1111== Unified Memory profiling result:\n",
            "Device \"Tesla K80 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "       6  1.3333MB  896.00KB  2.0000MB  8.000000MB  1.268576ms  Host To Device\n",
            "     102  120.47KB  4.0000KB  0.9961MB  12.00000MB  1.750112ms  Device To Host\n",
            "Total CPU Page faults: 51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGXPJXf77Nm2",
        "outputId": "67888fa0-8de2-4c1c-ee83-67d12b64b6b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!time ./add2"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max error: 0\n",
            "\n",
            "real\t0m0.672s\n",
            "user\t0m0.516s\n",
            "sys\t0m0.146s\n"
          ]
        }
      ]
    }
  ]
}